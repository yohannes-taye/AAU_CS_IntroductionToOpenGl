{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNVvgyqM1FhTV90OFV6Epzf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yohannes-taye/AAU_CS_IntroductionToOpenGl/blob/main/transcript.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub\n",
        "!apt-get install ffmpeg\n",
        "!pip install yt-dlp webvtt-py\n",
        "!pip install googletrans==4.0.0-rc1\n",
        "!pip install requests\n",
        "!pip install pypinyin\n",
        "!pip install jieba\n",
        "!pip install genanki\n",
        "!pip install openai"
      ],
      "metadata": {
        "id": "ZSit3btZrt5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### List all available subtitles from the video. If youre looking to generate chinese audio cards then look for `zh-Hans`"
      ],
      "metadata": {
        "id": "9TfamrqEsB6r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download subtitles (vtt format)\n",
        "#!yt-dlp --write-auto-sub --sub-lang en --sub-format vtt --skip-download https://www.youtube.com/watch?v=g1LsFSO1mbY&t=2s\n",
        "!yt-dlp --list-subs https://www.youtube.com/watch?v=g1LsFSO1mbY&t=2s\n",
        "#should appear as zh-Hans"
      ],
      "metadata": {
        "id": "2UNToKdChTTI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b2a6b6e-babc-42db-c88f-c803ce2e4a1b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=g1LsFSO1mbY\n",
            "[youtube] g1LsFSO1mbY: Downloading webpage\n",
            "[youtube] g1LsFSO1mbY: Downloading tv client config\n",
            "[youtube] g1LsFSO1mbY: Downloading player 9a279502-main\n",
            "[youtube] g1LsFSO1mbY: Downloading tv player API JSON\n",
            "[youtube] g1LsFSO1mbY: Downloading ios player API JSON\n",
            "[youtube] g1LsFSO1mbY: Downloading m3u8 information\n",
            "[info] Available automatic captions for g1LsFSO1mbY:\n",
            "\u001b[0;33mLanguage\u001b[0m        \u001b[0;33mName\u001b[0m                                            \u001b[0;33mFormats\u001b[0m\n",
            "zh-Hans                                                         vtt\n",
            "en                                                              vtt\n",
            "ab-zh-Hans      Abkhazian from Chinese (Simplified)             vtt, ttml, srv3, srv2, srv1, json3\n",
            "aa-zh-Hans      Afar from Chinese (Simplified)                  vtt, ttml, srv3, srv2, srv1, json3\n",
            "af-zh-Hans      Afrikaans from Chinese (Simplified)             vtt, ttml, srv3, srv2, srv1, json3\n",
            "ak-zh-Hans      Akan from Chinese (Simplified)                  vtt, ttml, srv3, srv2, srv1, json3\n",
            "sq-zh-Hans      Albanian from Chinese (Simplified)              vtt, ttml, srv3, srv2, srv1, json3\n",
            "am-zh-Hans      Amharic from Chinese (Simplified)               vtt, ttml, srv3, srv2, srv1, json3\n",
            "ar-zh-Hans      Arabic from Chinese (Simplified)                vtt, ttml, srv3, srv2, srv1, json3\n",
            "hy-zh-Hans      Armenian from Chinese (Simplified)              vtt, ttml, srv3, srv2, srv1, json3\n",
            "as-zh-Hans      Assamese from Chinese (Simplified)              vtt, ttml, srv3, srv2, srv1, json3\n",
            "ay-zh-Hans      Aymara from Chinese (Simplified)                vtt, ttml, srv3, srv2, srv1, json3\n",
            "az-zh-Hans      Azerbaijani from Chinese (Simplified)           vtt, ttml, srv3, srv2, srv1, json3\n",
            "bn-zh-Hans      Bangla from Chinese (Simplified)                vtt, ttml, srv3, srv2, srv1, json3\n",
            "ba-zh-Hans      Bashkir from Chinese (Simplified)               vtt, ttml, srv3, srv2, srv1, json3\n",
            "eu-zh-Hans      Basque from Chinese (Simplified)                vtt, ttml, srv3, srv2, srv1, json3\n",
            "be-zh-Hans      Belarusian from Chinese (Simplified)            vtt, ttml, srv3, srv2, srv1, json3\n",
            "bho-zh-Hans     Bhojpuri from Chinese (Simplified)              vtt, ttml, srv3, srv2, srv1, json3\n",
            "bs-zh-Hans      Bosnian from Chinese (Simplified)               vtt, ttml, srv3, srv2, srv1, json3\n",
            "br-zh-Hans      Breton from Chinese (Simplified)                vtt, ttml, srv3, srv2, srv1, json3\n",
            "bg-zh-Hans      Bulgarian from Chinese (Simplified)             vtt, ttml, srv3, srv2, srv1, json3\n",
            "my-zh-Hans      Burmese from Chinese (Simplified)               vtt, ttml, srv3, srv2, srv1, json3\n",
            "ca-zh-Hans      Catalan from Chinese (Simplified)               vtt, ttml, srv3, srv2, srv1, json3\n",
            "ceb-zh-Hans     Cebuano from Chinese (Simplified)               vtt, ttml, srv3, srv2, srv1, json3\n",
            "zh-Hans-zh-Hans Chinese (Simplified) from Chinese (Simplified)  vtt, ttml, srv3, srv2, srv1, json3\n",
            "zh-Hant-zh-Hans Chinese (Traditional) from Chinese (Simplified) vtt, ttml, srv3, srv2, srv1, json3\n",
            "co-zh-Hans      Corsican from Chinese (Simplified)              vtt, ttml, srv3, srv2, srv1, json3\n",
            "hr-zh-Hans      Croatian from Chinese (Simplified)              vtt, ttml, srv3, srv2, srv1, json3\n",
            "cs-zh-Hans      Czech from Chinese (Simplified)                 vtt, ttml, srv3, srv2, srv1, json3\n",
            "da-zh-Hans      Danish from Chinese (Simplified)                vtt, ttml, srv3, srv2, srv1, json3\n",
            "dv-zh-Hans      Divehi from Chinese (Simplified)                vtt, ttml, srv3, srv2, srv1, json3\n",
            "nl-zh-Hans      Dutch from Chinese (Simplified)                 vtt, ttml, srv3, srv2, srv1, json3\n",
            "dz-zh-Hans      Dzongkha from Chinese (Simplified)              vtt, ttml, srv3, srv2, srv1, json3\n",
            "en-zh-Hans      English from Chinese (Simplified)               vtt, ttml, srv3, srv2, srv1, json3\n",
            "eo-zh-Hans      Esperanto from Chinese (Simplified)             vtt, ttml, srv3, srv2, srv1, json3\n",
            "et-zh-Hans      Estonian from Chinese (Simplified)              vtt, ttml, srv3, srv2, srv1, json3\n",
            "ee-zh-Hans      Ewe from Chinese (Simplified)                   vtt, ttml, srv3, srv2, srv1, json3\n",
            "fo-zh-Hans      Faroese from Chinese (Simplified)               vtt, ttml, srv3, srv2, srv1, json3\n",
            "fj-zh-Hans      Fijian from Chinese (Simplified)                vtt, ttml, srv3, srv2, srv1, json3\n",
            "fil-zh-Hans     Filipino from Chinese (Simplified)              vtt, ttml, srv3, srv2, srv1, json3\n",
            "fi-zh-Hans      Finnish from Chinese (Simplified)               vtt, ttml, srv3, srv2, srv1, json3\n",
            "fr-zh-Hans      French from Chinese (Simplified)                vtt, ttml, srv3, srv2, srv1, json3\n",
            "gaa-zh-Hans     Ga from Chinese (Simplified)                    vtt, ttml, srv3, srv2, srv1, json3\n",
            "gl-zh-Hans      Galician from Chinese (Simplified)              vtt, ttml, srv3, srv2, srv1, json3\n",
            "lg-zh-Hans      Ganda from Chinese (Simplified)                 vtt, ttml, srv3, srv2, srv1, json3\n",
            "ka-zh-Hans      Georgian from Chinese (Simplified)              vtt, ttml, srv3, srv2, srv1, json3\n",
            "de-zh-Hans      German from Chinese (Simplified)                vtt, ttml, srv3, srv2, srv1, json3\n",
            "el-zh-Hans      Greek from Chinese (Simplified)                 vtt, ttml, srv3, srv2, srv1, json3\n",
            "gn-zh-Hans      Guarani from Chinese (Simplified)               vtt, ttml, srv3, srv2, srv1, json3\n",
            "gu-zh-Hans      Gujarati from Chinese (Simplified)              vtt, ttml, srv3, srv2, srv1, json3\n",
            "ht-zh-Hans      Haitian Creole from Chinese (Simplified)        vtt, ttml, srv3, srv2, srv1, json3\n",
            "ha-zh-Hans      Hausa from Chinese (Simplified)                 vtt, ttml, srv3, srv2, srv1, json3\n",
            "haw-zh-Hans     Hawaiian from Chinese (Simplified)              vtt, ttml, srv3, srv2, srv1, json3\n",
            "iw-zh-Hans      Hebrew from Chinese (Simplified)                vtt, ttml, srv3, srv2, srv1, json3\n",
            "hi-zh-Hans      Hindi from Chinese (Simplified)                 vtt, ttml, srv3, srv2, srv1, json3\n",
            "hmn-zh-Hans     Hmong from Chinese (Simplified)                 vtt, ttml, srv3, srv2, srv1, json3\n",
            "hu-zh-Hans      Hungarian from Chinese (Simplified)             vtt, ttml, srv3, srv2, srv1, json3\n",
            "is-zh-Hans      Icelandic from Chinese (Simplified)             vtt, ttml, srv3, srv2, srv1, json3\n",
            "ig-zh-Hans      Igbo from Chinese (Simplified)                  vtt, ttml, srv3, srv2, srv1, json3\n",
            "id-zh-Hans      Indonesian from Chinese (Simplified)            vtt, ttml, srv3, srv2, srv1, json3\n",
            "iu-zh-Hans      Inuktitut from Chinese (Simplified)             vtt, ttml, srv3, srv2, srv1, json3\n",
            "ga-zh-Hans      Irish from Chinese (Simplified)                 vtt, ttml, srv3, srv2, srv1, json3\n",
            "it-zh-Hans      Italian from Chinese (Simplified)               vtt, ttml, srv3, srv2, srv1, json3\n",
            "ja-zh-Hans      Japanese from Chinese (Simplified)              vtt, ttml, srv3, srv2, srv1, json3\n",
            "jv-zh-Hans      Javanese from Chinese (Simplified)              vtt, ttml, srv3, srv2, srv1, json3\n",
            "kl-zh-Hans      Kalaallisut from Chinese (Simplified)           vtt, ttml, srv3, srv2, srv1, json3\n",
            "kn-zh-Hans      Kannada from Chinese (Simplified)               vtt, ttml, srv3, srv2, srv1, json3\n",
            "kk-zh-Hans      Kazakh from Chinese (Simplified)                vtt, ttml, srv3, srv2, srv1, json3\n",
            "kha-zh-Hans     Khasi from Chinese (Simplified)                 vtt, ttml, srv3, srv2, srv1, json3\n",
            "km-zh-Hans      Khmer from Chinese (Simplified)                 vtt, ttml, srv3, srv2, srv1, json3\n",
            "rw-zh-Hans      Kinyarwanda from Chinese (Simplified)           vtt, ttml, srv3, srv2, srv1, json3\n",
            "ko-zh-Hans      Korean from Chinese (Simplified)                vtt, ttml, srv3, srv2, srv1, json3\n",
            "kri-zh-Hans     Krio from Chinese (Simplified)                  vtt, ttml, srv3, srv2, srv1, json3\n",
            "ku-zh-Hans      Kurdish from Chinese (Simplified)               vtt, ttml, srv3, srv2, srv1, json3\n",
            "ky-zh-Hans      Kyrgyz from Chinese (Simplified)                vtt, ttml, srv3, srv2, srv1, json3\n",
            "lo-zh-Hans      Lao from Chinese (Simplified)                   vtt, ttml, srv3, srv2, srv1, json3\n",
            "la-zh-Hans      Latin from Chinese (Simplified)                 vtt, ttml, srv3, srv2, srv1, json3\n",
            "lv-zh-Hans      Latvian from Chinese (Simplified)               vtt, ttml, srv3, srv2, srv1, json3\n",
            "ln-zh-Hans      Lingala from Chinese (Simplified)               vtt, ttml, srv3, srv2, srv1, json3\n",
            "lt-zh-Hans      Lithuanian from Chinese (Simplified)            vtt, ttml, srv3, srv2, srv1, json3\n",
            "lua-zh-Hans     Luba-Lulua from Chinese (Simplified)            vtt, ttml, srv3, srv2, srv1, json3\n",
            "luo-zh-Hans     Luo from Chinese (Simplified)                   vtt, ttml, srv3, srv2, srv1, json3\n",
            "lb-zh-Hans      Luxembourgish from Chinese (Simplified)         vtt, ttml, srv3, srv2, srv1, json3\n",
            "mk-zh-Hans      Macedonian from Chinese (Simplified)            vtt, ttml, srv3, srv2, srv1, json3\n",
            "mg-zh-Hans      Malagasy from Chinese (Simplified)              vtt, ttml, srv3, srv2, srv1, json3\n",
            "ms-zh-Hans      Malay from Chinese (Simplified)                 vtt, ttml, srv3, srv2, srv1, json3\n",
            "ml-zh-Hans      Malayalam from Chinese (Simplified)             vtt, ttml, srv3, srv2, srv1, json3\n",
            "mt-zh-Hans      Maltese from Chinese (Simplified)               vtt, ttml, srv3, srv2, srv1, json3\n",
            "gv-zh-Hans      Manx from Chinese (Simplified)                  vtt, ttml, srv3, srv2, srv1, json3\n",
            "mi-zh-Hans      Māori from Chinese (Simplified)                 vtt, ttml, srv3, srv2, srv1, json3\n",
            "mr-zh-Hans      Marathi from Chinese (Simplified)               vtt, ttml, srv3, srv2, srv1, json3\n",
            "mn-zh-Hans      Mongolian from Chinese (Simplified)             vtt, ttml, srv3, srv2, srv1, json3\n",
            "mfe-zh-Hans     Morisyen from Chinese (Simplified)              vtt, ttml, srv3, srv2, srv1, json3\n",
            "ne-zh-Hans      Nepali from Chinese (Simplified)                vtt, ttml, srv3, srv2, srv1, json3\n",
            "new-zh-Hans     Newari from Chinese (Simplified)                vtt, ttml, srv3, srv2, srv1, json3\n",
            "nso-zh-Hans     Northern Sotho from Chinese (Simplified)        vtt, ttml, srv3, srv2, srv1, json3\n",
            "no-zh-Hans      Norwegian from Chinese (Simplified)             vtt, ttml, srv3, srv2, srv1, json3\n",
            "ny-zh-Hans      Nyanja from Chinese (Simplified)                vtt, ttml, srv3, srv2, srv1, json3\n",
            "oc-zh-Hans      Occitan from Chinese (Simplified)               vtt, ttml, srv3, srv2, srv1, json3\n",
            "or-zh-Hans      Odia from Chinese (Simplified)                  vtt, ttml, srv3, srv2, srv1, json3\n",
            "om-zh-Hans      Oromo from Chinese (Simplified)                 vtt, ttml, srv3, srv2, srv1, json3\n",
            "os-zh-Hans      Ossetic from Chinese (Simplified)               vtt, ttml, srv3, srv2, srv1, json3\n",
            "pam-zh-Hans     Pampanga from Chinese (Simplified)              vtt, ttml, srv3, srv2, srv1, json3\n",
            "ps-zh-Hans      Pashto from Chinese (Simplified)                vtt, ttml, srv3, srv2, srv1, json3\n",
            "fa-zh-Hans      Persian from Chinese (Simplified)               vtt, ttml, srv3, srv2, srv1, json3\n",
            "pl-zh-Hans      Polish from Chinese (Simplified)                vtt, ttml, srv3, srv2, srv1, json3\n",
            "pt-zh-Hans      Portuguese from Chinese (Simplified)            vtt, ttml, srv3, srv2, srv1, json3\n",
            "pt-PT-zh-Hans   Portuguese (Portugal) from Chinese (Simplified) vtt, ttml, srv3, srv2, srv1, json3\n",
            "pa-zh-Hans      Punjabi from Chinese (Simplified)               vtt, ttml, srv3, srv2, srv1, json3\n",
            "qu-zh-Hans      Quechua from Chinese (Simplified)               vtt, ttml, srv3, srv2, srv1, json3\n",
            "ro-zh-Hans      Romanian from Chinese (Simplified)              vtt, ttml, srv3, srv2, srv1, json3\n",
            "rn-zh-Hans      Rundi from Chinese (Simplified)                 vtt, ttml, srv3, srv2, srv1, json3\n",
            "ru-zh-Hans      Russian from Chinese (Simplified)               vtt, ttml, srv3, srv2, srv1, json3\n",
            "sm-zh-Hans      Samoan from Chinese (Simplified)                vtt, ttml, srv3, srv2, srv1, json3\n",
            "sg-zh-Hans      Sango from Chinese (Simplified)                 vtt, ttml, srv3, srv2, srv1, json3\n",
            "sa-zh-Hans      Sanskrit from Chinese (Simplified)              vtt, ttml, srv3, srv2, srv1, json3\n",
            "gd-zh-Hans      Scottish Gaelic from Chinese (Simplified)       vtt, ttml, srv3, srv2, srv1, json3\n",
            "sr-zh-Hans      Serbian from Chinese (Simplified)               vtt, ttml, srv3, srv2, srv1, json3\n",
            "crs-zh-Hans     Seselwa Creole French from Chinese (Simplified) vtt, ttml, srv3, srv2, srv1, json3\n",
            "sn-zh-Hans      Shona from Chinese (Simplified)                 vtt, ttml, srv3, srv2, srv1, json3\n",
            "sd-zh-Hans      Sindhi from Chinese (Simplified)                vtt, ttml, srv3, srv2, srv1, json3\n",
            "si-zh-Hans      Sinhala from Chinese (Simplified)               vtt, ttml, srv3, srv2, srv1, json3\n",
            "sk-zh-Hans      Slovak from Chinese (Simplified)                vtt, ttml, srv3, srv2, srv1, json3\n",
            "sl-zh-Hans      Slovenian from Chinese (Simplified)             vtt, ttml, srv3, srv2, srv1, json3\n",
            "so-zh-Hans      Somali from Chinese (Simplified)                vtt, ttml, srv3, srv2, srv1, json3\n",
            "st-zh-Hans      Southern Sotho from Chinese (Simplified)        vtt, ttml, srv3, srv2, srv1, json3\n",
            "es-zh-Hans      Spanish from Chinese (Simplified)               vtt, ttml, srv3, srv2, srv1, json3\n",
            "su-zh-Hans      Sundanese from Chinese (Simplified)             vtt, ttml, srv3, srv2, srv1, json3\n",
            "sw-zh-Hans      Swahili from Chinese (Simplified)               vtt, ttml, srv3, srv2, srv1, json3\n",
            "ss-zh-Hans      Swati from Chinese (Simplified)                 vtt, ttml, srv3, srv2, srv1, json3\n",
            "sv-zh-Hans      Swedish from Chinese (Simplified)               vtt, ttml, srv3, srv2, srv1, json3\n",
            "tg-zh-Hans      Tajik from Chinese (Simplified)                 vtt, ttml, srv3, srv2, srv1, json3\n",
            "ta-zh-Hans      Tamil from Chinese (Simplified)                 vtt, ttml, srv3, srv2, srv1, json3\n",
            "tt-zh-Hans      Tatar from Chinese (Simplified)                 vtt, ttml, srv3, srv2, srv1, json3\n",
            "te-zh-Hans      Telugu from Chinese (Simplified)                vtt, ttml, srv3, srv2, srv1, json3\n",
            "th-zh-Hans      Thai from Chinese (Simplified)                  vtt, ttml, srv3, srv2, srv1, json3\n",
            "bo-zh-Hans      Tibetan from Chinese (Simplified)               vtt, ttml, srv3, srv2, srv1, json3\n",
            "ti-zh-Hans      Tigrinya from Chinese (Simplified)              vtt, ttml, srv3, srv2, srv1, json3\n",
            "to-zh-Hans      Tongan from Chinese (Simplified)                vtt, ttml, srv3, srv2, srv1, json3\n",
            "ts-zh-Hans      Tsonga from Chinese (Simplified)                vtt, ttml, srv3, srv2, srv1, json3\n",
            "tn-zh-Hans      Tswana from Chinese (Simplified)                vtt, ttml, srv3, srv2, srv1, json3\n",
            "tum-zh-Hans     Tumbuka from Chinese (Simplified)               vtt, ttml, srv3, srv2, srv1, json3\n",
            "tr-zh-Hans      Turkish from Chinese (Simplified)               vtt, ttml, srv3, srv2, srv1, json3\n",
            "tk-zh-Hans      Turkmen from Chinese (Simplified)               vtt, ttml, srv3, srv2, srv1, json3\n",
            "uk-zh-Hans      Ukrainian from Chinese (Simplified)             vtt, ttml, srv3, srv2, srv1, json3\n",
            "ur-zh-Hans      Urdu from Chinese (Simplified)                  vtt, ttml, srv3, srv2, srv1, json3\n",
            "ug-zh-Hans      Uyghur from Chinese (Simplified)                vtt, ttml, srv3, srv2, srv1, json3\n",
            "uz-zh-Hans      Uzbek from Chinese (Simplified)                 vtt, ttml, srv3, srv2, srv1, json3\n",
            "ve-zh-Hans      Venda from Chinese (Simplified)                 vtt, ttml, srv3, srv2, srv1, json3\n",
            "vi-zh-Hans      Vietnamese from Chinese (Simplified)            vtt, ttml, srv3, srv2, srv1, json3\n",
            "war-zh-Hans     Waray from Chinese (Simplified)                 vtt, ttml, srv3, srv2, srv1, json3\n",
            "cy-zh-Hans      Welsh from Chinese (Simplified)                 vtt, ttml, srv3, srv2, srv1, json3\n",
            "fy-zh-Hans      Western Frisian from Chinese (Simplified)       vtt, ttml, srv3, srv2, srv1, json3\n",
            "wo-zh-Hans      Wolof from Chinese (Simplified)                 vtt, ttml, srv3, srv2, srv1, json3\n",
            "xh-zh-Hans      Xhosa from Chinese (Simplified)                 vtt, ttml, srv3, srv2, srv1, json3\n",
            "yi-zh-Hans      Yiddish from Chinese (Simplified)               vtt, ttml, srv3, srv2, srv1, json3\n",
            "yo-zh-Hans      Yoruba from Chinese (Simplified)                vtt, ttml, srv3, srv2, srv1, json3\n",
            "zu-zh-Hans      Zulu from Chinese (Simplified)                  vtt, ttml, srv3, srv2, srv1, json3\n",
            "ab-en           Abkhazian from English                          vtt, ttml, srv3, srv2, srv1, json3\n",
            "aa-en           Afar from English                               vtt, ttml, srv3, srv2, srv1, json3\n",
            "af-en           Afrikaans from English                          vtt, ttml, srv3, srv2, srv1, json3\n",
            "ak-en           Akan from English                               vtt, ttml, srv3, srv2, srv1, json3\n",
            "sq-en           Albanian from English                           vtt, ttml, srv3, srv2, srv1, json3\n",
            "am-en           Amharic from English                            vtt, ttml, srv3, srv2, srv1, json3\n",
            "ar-en           Arabic from English                             vtt, ttml, srv3, srv2, srv1, json3\n",
            "hy-en           Armenian from English                           vtt, ttml, srv3, srv2, srv1, json3\n",
            "as-en           Assamese from English                           vtt, ttml, srv3, srv2, srv1, json3\n",
            "ay-en           Aymara from English                             vtt, ttml, srv3, srv2, srv1, json3\n",
            "az-en           Azerbaijani from English                        vtt, ttml, srv3, srv2, srv1, json3\n",
            "bn-en           Bangla from English                             vtt, ttml, srv3, srv2, srv1, json3\n",
            "ba-en           Bashkir from English                            vtt, ttml, srv3, srv2, srv1, json3\n",
            "eu-en           Basque from English                             vtt, ttml, srv3, srv2, srv1, json3\n",
            "be-en           Belarusian from English                         vtt, ttml, srv3, srv2, srv1, json3\n",
            "bho-en          Bhojpuri from English                           vtt, ttml, srv3, srv2, srv1, json3\n",
            "bs-en           Bosnian from English                            vtt, ttml, srv3, srv2, srv1, json3\n",
            "br-en           Breton from English                             vtt, ttml, srv3, srv2, srv1, json3\n",
            "bg-en           Bulgarian from English                          vtt, ttml, srv3, srv2, srv1, json3\n",
            "my-en           Burmese from English                            vtt, ttml, srv3, srv2, srv1, json3\n",
            "ca-en           Catalan from English                            vtt, ttml, srv3, srv2, srv1, json3\n",
            "ceb-en          Cebuano from English                            vtt, ttml, srv3, srv2, srv1, json3\n",
            "zh-Hans-en      Chinese (Simplified) from English               vtt, ttml, srv3, srv2, srv1, json3\n",
            "zh-Hant-en      Chinese (Traditional) from English              vtt, ttml, srv3, srv2, srv1, json3\n",
            "co-en           Corsican from English                           vtt, ttml, srv3, srv2, srv1, json3\n",
            "hr-en           Croatian from English                           vtt, ttml, srv3, srv2, srv1, json3\n",
            "cs-en           Czech from English                              vtt, ttml, srv3, srv2, srv1, json3\n",
            "da-en           Danish from English                             vtt, ttml, srv3, srv2, srv1, json3\n",
            "dv-en           Divehi from English                             vtt, ttml, srv3, srv2, srv1, json3\n",
            "nl-en           Dutch from English                              vtt, ttml, srv3, srv2, srv1, json3\n",
            "dz-en           Dzongkha from English                           vtt, ttml, srv3, srv2, srv1, json3\n",
            "en-en           English from English                            vtt, ttml, srv3, srv2, srv1, json3\n",
            "eo-en           Esperanto from English                          vtt, ttml, srv3, srv2, srv1, json3\n",
            "et-en           Estonian from English                           vtt, ttml, srv3, srv2, srv1, json3\n",
            "ee-en           Ewe from English                                vtt, ttml, srv3, srv2, srv1, json3\n",
            "fo-en           Faroese from English                            vtt, ttml, srv3, srv2, srv1, json3\n",
            "fj-en           Fijian from English                             vtt, ttml, srv3, srv2, srv1, json3\n",
            "fil-en          Filipino from English                           vtt, ttml, srv3, srv2, srv1, json3\n",
            "fi-en           Finnish from English                            vtt, ttml, srv3, srv2, srv1, json3\n",
            "fr-en           French from English                             vtt, ttml, srv3, srv2, srv1, json3\n",
            "gaa-en          Ga from English                                 vtt, ttml, srv3, srv2, srv1, json3\n",
            "gl-en           Galician from English                           vtt, ttml, srv3, srv2, srv1, json3\n",
            "lg-en           Ganda from English                              vtt, ttml, srv3, srv2, srv1, json3\n",
            "ka-en           Georgian from English                           vtt, ttml, srv3, srv2, srv1, json3\n",
            "de-en           German from English                             vtt, ttml, srv3, srv2, srv1, json3\n",
            "el-en           Greek from English                              vtt, ttml, srv3, srv2, srv1, json3\n",
            "gn-en           Guarani from English                            vtt, ttml, srv3, srv2, srv1, json3\n",
            "gu-en           Gujarati from English                           vtt, ttml, srv3, srv2, srv1, json3\n",
            "ht-en           Haitian Creole from English                     vtt, ttml, srv3, srv2, srv1, json3\n",
            "ha-en           Hausa from English                              vtt, ttml, srv3, srv2, srv1, json3\n",
            "haw-en          Hawaiian from English                           vtt, ttml, srv3, srv2, srv1, json3\n",
            "iw-en           Hebrew from English                             vtt, ttml, srv3, srv2, srv1, json3\n",
            "hi-en           Hindi from English                              vtt, ttml, srv3, srv2, srv1, json3\n",
            "hmn-en          Hmong from English                              vtt, ttml, srv3, srv2, srv1, json3\n",
            "hu-en           Hungarian from English                          vtt, ttml, srv3, srv2, srv1, json3\n",
            "is-en           Icelandic from English                          vtt, ttml, srv3, srv2, srv1, json3\n",
            "ig-en           Igbo from English                               vtt, ttml, srv3, srv2, srv1, json3\n",
            "id-en           Indonesian from English                         vtt, ttml, srv3, srv2, srv1, json3\n",
            "iu-en           Inuktitut from English                          vtt, ttml, srv3, srv2, srv1, json3\n",
            "ga-en           Irish from English                              vtt, ttml, srv3, srv2, srv1, json3\n",
            "it-en           Italian from English                            vtt, ttml, srv3, srv2, srv1, json3\n",
            "ja-en           Japanese from English                           vtt, ttml, srv3, srv2, srv1, json3\n",
            "jv-en           Javanese from English                           vtt, ttml, srv3, srv2, srv1, json3\n",
            "kl-en           Kalaallisut from English                        vtt, ttml, srv3, srv2, srv1, json3\n",
            "kn-en           Kannada from English                            vtt, ttml, srv3, srv2, srv1, json3\n",
            "kk-en           Kazakh from English                             vtt, ttml, srv3, srv2, srv1, json3\n",
            "kha-en          Khasi from English                              vtt, ttml, srv3, srv2, srv1, json3\n",
            "km-en           Khmer from English                              vtt, ttml, srv3, srv2, srv1, json3\n",
            "rw-en           Kinyarwanda from English                        vtt, ttml, srv3, srv2, srv1, json3\n",
            "ko-en           Korean from English                             vtt, ttml, srv3, srv2, srv1, json3\n",
            "kri-en          Krio from English                               vtt, ttml, srv3, srv2, srv1, json3\n",
            "ku-en           Kurdish from English                            vtt, ttml, srv3, srv2, srv1, json3\n",
            "ky-en           Kyrgyz from English                             vtt, ttml, srv3, srv2, srv1, json3\n",
            "lo-en           Lao from English                                vtt, ttml, srv3, srv2, srv1, json3\n",
            "la-en           Latin from English                              vtt, ttml, srv3, srv2, srv1, json3\n",
            "lv-en           Latvian from English                            vtt, ttml, srv3, srv2, srv1, json3\n",
            "ln-en           Lingala from English                            vtt, ttml, srv3, srv2, srv1, json3\n",
            "lt-en           Lithuanian from English                         vtt, ttml, srv3, srv2, srv1, json3\n",
            "lua-en          Luba-Lulua from English                         vtt, ttml, srv3, srv2, srv1, json3\n",
            "luo-en          Luo from English                                vtt, ttml, srv3, srv2, srv1, json3\n",
            "lb-en           Luxembourgish from English                      vtt, ttml, srv3, srv2, srv1, json3\n",
            "mk-en           Macedonian from English                         vtt, ttml, srv3, srv2, srv1, json3\n",
            "mg-en           Malagasy from English                           vtt, ttml, srv3, srv2, srv1, json3\n",
            "ms-en           Malay from English                              vtt, ttml, srv3, srv2, srv1, json3\n",
            "ml-en           Malayalam from English                          vtt, ttml, srv3, srv2, srv1, json3\n",
            "mt-en           Maltese from English                            vtt, ttml, srv3, srv2, srv1, json3\n",
            "gv-en           Manx from English                               vtt, ttml, srv3, srv2, srv1, json3\n",
            "mi-en           Māori from English                              vtt, ttml, srv3, srv2, srv1, json3\n",
            "mr-en           Marathi from English                            vtt, ttml, srv3, srv2, srv1, json3\n",
            "mn-en           Mongolian from English                          vtt, ttml, srv3, srv2, srv1, json3\n",
            "mfe-en          Morisyen from English                           vtt, ttml, srv3, srv2, srv1, json3\n",
            "ne-en           Nepali from English                             vtt, ttml, srv3, srv2, srv1, json3\n",
            "new-en          Newari from English                             vtt, ttml, srv3, srv2, srv1, json3\n",
            "nso-en          Northern Sotho from English                     vtt, ttml, srv3, srv2, srv1, json3\n",
            "no-en           Norwegian from English                          vtt, ttml, srv3, srv2, srv1, json3\n",
            "ny-en           Nyanja from English                             vtt, ttml, srv3, srv2, srv1, json3\n",
            "oc-en           Occitan from English                            vtt, ttml, srv3, srv2, srv1, json3\n",
            "or-en           Odia from English                               vtt, ttml, srv3, srv2, srv1, json3\n",
            "om-en           Oromo from English                              vtt, ttml, srv3, srv2, srv1, json3\n",
            "os-en           Ossetic from English                            vtt, ttml, srv3, srv2, srv1, json3\n",
            "pam-en          Pampanga from English                           vtt, ttml, srv3, srv2, srv1, json3\n",
            "ps-en           Pashto from English                             vtt, ttml, srv3, srv2, srv1, json3\n",
            "fa-en           Persian from English                            vtt, ttml, srv3, srv2, srv1, json3\n",
            "pl-en           Polish from English                             vtt, ttml, srv3, srv2, srv1, json3\n",
            "pt-en           Portuguese from English                         vtt, ttml, srv3, srv2, srv1, json3\n",
            "pt-PT-en        Portuguese (Portugal) from English              vtt, ttml, srv3, srv2, srv1, json3\n",
            "pa-en           Punjabi from English                            vtt, ttml, srv3, srv2, srv1, json3\n",
            "qu-en           Quechua from English                            vtt, ttml, srv3, srv2, srv1, json3\n",
            "ro-en           Romanian from English                           vtt, ttml, srv3, srv2, srv1, json3\n",
            "rn-en           Rundi from English                              vtt, ttml, srv3, srv2, srv1, json3\n",
            "ru-en           Russian from English                            vtt, ttml, srv3, srv2, srv1, json3\n",
            "sm-en           Samoan from English                             vtt, ttml, srv3, srv2, srv1, json3\n",
            "sg-en           Sango from English                              vtt, ttml, srv3, srv2, srv1, json3\n",
            "sa-en           Sanskrit from English                           vtt, ttml, srv3, srv2, srv1, json3\n",
            "gd-en           Scottish Gaelic from English                    vtt, ttml, srv3, srv2, srv1, json3\n",
            "sr-en           Serbian from English                            vtt, ttml, srv3, srv2, srv1, json3\n",
            "crs-en          Seselwa Creole French from English              vtt, ttml, srv3, srv2, srv1, json3\n",
            "sn-en           Shona from English                              vtt, ttml, srv3, srv2, srv1, json3\n",
            "sd-en           Sindhi from English                             vtt, ttml, srv3, srv2, srv1, json3\n",
            "si-en           Sinhala from English                            vtt, ttml, srv3, srv2, srv1, json3\n",
            "sk-en           Slovak from English                             vtt, ttml, srv3, srv2, srv1, json3\n",
            "sl-en           Slovenian from English                          vtt, ttml, srv3, srv2, srv1, json3\n",
            "so-en           Somali from English                             vtt, ttml, srv3, srv2, srv1, json3\n",
            "st-en           Southern Sotho from English                     vtt, ttml, srv3, srv2, srv1, json3\n",
            "es-en           Spanish from English                            vtt, ttml, srv3, srv2, srv1, json3\n",
            "su-en           Sundanese from English                          vtt, ttml, srv3, srv2, srv1, json3\n",
            "sw-en           Swahili from English                            vtt, ttml, srv3, srv2, srv1, json3\n",
            "ss-en           Swati from English                              vtt, ttml, srv3, srv2, srv1, json3\n",
            "sv-en           Swedish from English                            vtt, ttml, srv3, srv2, srv1, json3\n",
            "tg-en           Tajik from English                              vtt, ttml, srv3, srv2, srv1, json3\n",
            "ta-en           Tamil from English                              vtt, ttml, srv3, srv2, srv1, json3\n",
            "tt-en           Tatar from English                              vtt, ttml, srv3, srv2, srv1, json3\n",
            "te-en           Telugu from English                             vtt, ttml, srv3, srv2, srv1, json3\n",
            "th-en           Thai from English                               vtt, ttml, srv3, srv2, srv1, json3\n",
            "bo-en           Tibetan from English                            vtt, ttml, srv3, srv2, srv1, json3\n",
            "ti-en           Tigrinya from English                           vtt, ttml, srv3, srv2, srv1, json3\n",
            "to-en           Tongan from English                             vtt, ttml, srv3, srv2, srv1, json3\n",
            "ts-en           Tsonga from English                             vtt, ttml, srv3, srv2, srv1, json3\n",
            "tn-en           Tswana from English                             vtt, ttml, srv3, srv2, srv1, json3\n",
            "tum-en          Tumbuka from English                            vtt, ttml, srv3, srv2, srv1, json3\n",
            "tr-en           Turkish from English                            vtt, ttml, srv3, srv2, srv1, json3\n",
            "tk-en           Turkmen from English                            vtt, ttml, srv3, srv2, srv1, json3\n",
            "uk-en           Ukrainian from English                          vtt, ttml, srv3, srv2, srv1, json3\n",
            "ur-en           Urdu from English                               vtt, ttml, srv3, srv2, srv1, json3\n",
            "ug-en           Uyghur from English                             vtt, ttml, srv3, srv2, srv1, json3\n",
            "uz-en           Uzbek from English                              vtt, ttml, srv3, srv2, srv1, json3\n",
            "ve-en           Venda from English                              vtt, ttml, srv3, srv2, srv1, json3\n",
            "vi-en           Vietnamese from English                         vtt, ttml, srv3, srv2, srv1, json3\n",
            "war-en          Waray from English                              vtt, ttml, srv3, srv2, srv1, json3\n",
            "cy-en           Welsh from English                              vtt, ttml, srv3, srv2, srv1, json3\n",
            "fy-en           Western Frisian from English                    vtt, ttml, srv3, srv2, srv1, json3\n",
            "wo-en           Wolof from English                              vtt, ttml, srv3, srv2, srv1, json3\n",
            "xh-en           Xhosa from English                              vtt, ttml, srv3, srv2, srv1, json3\n",
            "yi-en           Yiddish from English                            vtt, ttml, srv3, srv2, srv1, json3\n",
            "yo-en           Yoruba from English                             vtt, ttml, srv3, srv2, srv1, json3\n",
            "zu-en           Zulu from English                               vtt, ttml, srv3, srv2, srv1, json3\n",
            "[info] Available subtitles for g1LsFSO1mbY:\n",
            "\u001b[0;33mLanguage\u001b[0m \u001b[0;33mName\u001b[0m                 \u001b[0;33mFormats\u001b[0m\n",
            "zh-Hans  Chinese (Simplified) vtt, ttml, srv3, srv2, srv1, json3\n",
            "en       English              vtt, ttml, srv3, srv2, srv1, json3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download transcript. Add language using the flag `--sub-lang zh-Hans`"
      ],
      "metadata": {
        "id": "PSl4_t5bsSF-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!yt-dlp --write-sub --sub-lang zh-Hans --sub-format vtt --skip-download https://www.youtube.com/watch?v=g1LsFSO1mbY&t=2s\n"
      ],
      "metadata": {
        "id": "eqbgCocsiRKO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ad49085-d021-459f-a229-e52cf556a40f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=g1LsFSO1mbY\n",
            "[youtube] g1LsFSO1mbY: Downloading webpage\n",
            "[youtube] g1LsFSO1mbY: Downloading tv client config\n",
            "[youtube] g1LsFSO1mbY: Downloading player 753b1819-main\n",
            "[youtube] g1LsFSO1mbY: Downloading tv player API JSON\n",
            "[youtube] g1LsFSO1mbY: Downloading ios player API JSON\n",
            "[youtube] g1LsFSO1mbY: Downloading m3u8 information\n",
            "[info] g1LsFSO1mbY: Downloading subtitles: zh-Hans\n",
            "[info] g1LsFSO1mbY: Downloading 1 format(s): 616+251\n",
            "[info] Writing video subtitles to: 史上最值钱的那些公司 了解一下~ [g1LsFSO1mbY].zh-Hans.vtt\n",
            "[download] Destination: 史上最值钱的那些公司 了解一下~ [g1LsFSO1mbY].zh-Hans.vtt\n",
            "\u001b[K[download] 100% of   34.04KiB in \u001b[1;37m00:00:00\u001b[0m at \u001b[0;32m1.18MiB/s\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download EditThisCOokie extention for chrome and export cookie for youtube video. use netscape format.\n",
        "\n",
        "### Then the script below will download the audio file\n",
        "\n",
        "Download link:\n",
        "https://chromewebstore.google.com/detail/editthiscookie-v3/ojfebgpkimhlhcblbalbfjblapadhbol"
      ],
      "metadata": {
        "id": "MpOyZu2btP4H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!yt-dlp --cookies /content/cookie.txt -f bestaudio --extract-audio --audio-format mp3 --audio-quality 0 --output \"%(title)s.%(ext)s\" https://www.youtube.com/watch?v=g1LsFSO1mbY&t=2s\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yHEREFClDgh",
        "outputId": "2b66284e-4a15-48e4-8fdf-7bada34c967b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: skipping cookie file entry due to invalid length 1: 'enable_testing()\\n'\n",
            "WARNING: skipping cookie file entry due to invalid length 1: 'add_subdirectory(${CMAKE_SOURCE_DIR}/3rdparty/googletest ${CMAKE_BINARY_DIR}/googletest)\\n'\n",
            "WARNING: skipping cookie file entry due to invalid length 1: 'add_subdirectory(basic)\\n'\n",
            "WARNING: skipping cookie file entry due to invalid length 1: 'add_subdirectory(capture)\\n'\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=g1LsFSO1mbY\n",
            "[youtube] g1LsFSO1mbY: Downloading webpage\n",
            "[youtube] g1LsFSO1mbY: Downloading tv client config\n",
            "[youtube] g1LsFSO1mbY: Downloading player 9a279502-main\n",
            "[youtube] g1LsFSO1mbY: Downloading tv player API JSON\n",
            "[info] g1LsFSO1mbY: Downloading 1 format(s): 251\n",
            "[download] Destination: 史上最值钱的那些公司 了解一下~.webm\n",
            "\u001b[K[download] 100% of   17.85MiB in \u001b[1;37m00:00:01\u001b[0m at \u001b[0;32m14.87MiB/s\u001b[0m\n",
            "[ExtractAudio] Destination: 史上最值钱的那些公司 了解一下~.mp3\n",
            "Deleting original file 史上最值钱的那些公司 了解一下~.webm (pass -k to keep)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import webvtt\n",
        "import json\n",
        "\n",
        "# Function to decode unicode escape sequences properly\n",
        "def decode_unicode_escape(text):\n",
        "    # Ensuring proper decoding if needed\n",
        "    return text.encode('utf-8').decode('utf-8')\n",
        "\n",
        "def vtt_to_json(vtt_file, json_out):\n",
        "    transcript = []\n",
        "\n",
        "    # Read the .vtt file using webvtt\n",
        "    for caption in webvtt.read(vtt_file):\n",
        "        start = convert_timestamp(caption.start)\n",
        "        end = convert_timestamp(caption.end)\n",
        "\n",
        "        # Directly assign text, as it's already decoded correctly by webvtt\n",
        "        decoded_text = caption.text.strip().replace('\\n', ' ')\n",
        "\n",
        "        # Append the caption data to the transcript\n",
        "        transcript.append({\n",
        "            \"start\": start,\n",
        "            \"end\": end,\n",
        "            \"text\": decoded_text\n",
        "        })\n",
        "\n",
        "    # Write the decoded transcript to a JSON file with proper encoding\n",
        "    with open(json_out, 'w', encoding='utf-8') as f:\n",
        "        json.dump(transcript, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "def convert_timestamp(timestamp):\n",
        "    h, m, s = timestamp.split(\":\")\n",
        "    s, ms = s.split(\".\")\n",
        "    return int(h)*3600 + int(m)*60 + int(s) + int(ms)/1000.0\n",
        "\n",
        "# Example usage\n",
        "vtt_file = \"/content/史上最值钱的那些公司 了解一下~ [g1LsFSO1mbY].zh-Hans.vtt\"  # Replace with actual .vtt file path\n",
        "json_out = \"transcript.json\"\n",
        "vtt_to_json(vtt_file, json_out)\n"
      ],
      "metadata": {
        "id": "RNZkzPhKywW5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split audio using provided transcript."
      ],
      "metadata": {
        "id": "CQCvG-drrfGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "import os\n",
        "import json\n",
        "\n",
        "# Load the transcript JSON file\n",
        "with open('transcript.json', 'r', encoding='utf-8') as f:\n",
        "    transcript = json.load(f)\n",
        "\n",
        "# Load the audio file (replace with the actual file name)\n",
        "audio_file = '/content/史上最值钱的那些公司 了解一下~.mp3'  # Replace with the path to your audio file\n",
        "audio = AudioSegment.from_file(audio_file)\n",
        "\n",
        "# Create an output directory to save the audio chunks\n",
        "output_dir = \"/content/split_audio\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Initialize a variable to hold the combined audio chunks\n",
        "combined_audio = None\n",
        "combined_text = \"\"\n",
        "chunk_counter = 0\n",
        "\n",
        "# Loop through the transcript and split the audio in pairs\n",
        "for i in range(0, len(transcript) - 1, 2):  # Step by 2 to process pairs\n",
        "    # Get the start and end times for the current and next sentence\n",
        "    start_ms_1 = int(transcript[i][\"start\"] * 1000)  # Convert to milliseconds\n",
        "    end_ms_1 = int(transcript[i][\"end\"] * 1000)  # Convert to milliseconds\n",
        "    text_1 = transcript[i][\"text\"]\n",
        "\n",
        "    start_ms_2 = int(transcript[i+1][\"start\"] * 1000)  # Convert to milliseconds\n",
        "    end_ms_2 = int(transcript[i+1][\"end\"] * 1000)  # Convert to milliseconds\n",
        "    text_2 = transcript[i+1][\"text\"]\n",
        "\n",
        "    # Extract the audio chunks for both entries\n",
        "    chunk_1 = audio[start_ms_1:end_ms_1]\n",
        "    chunk_2 = audio[start_ms_2:end_ms_2]\n",
        "\n",
        "    # Combine the two chunks\n",
        "    combined_audio = chunk_1 + chunk_2\n",
        "\n",
        "    # Combine the text from both entries\n",
        "    combined_text = text_1 + text_2\n",
        "\n",
        "    # Save the combined audio chunk as a new file\n",
        "    combined_filename = f\"combined_chunk_{chunk_counter:04d}.mp3\"  # File name format\n",
        "    combined_path = os.path.join(output_dir, combined_filename)\n",
        "    combined_audio.export(combined_path, format=\"mp3\")\n",
        "\n",
        "    # Save the corresponding combined text as a .txt file\n",
        "    with open(os.path.join(output_dir, f\"combined_chunk_{chunk_counter:04d}.txt\"), 'w', encoding='utf-8') as txt_file:\n",
        "        txt_file.write(combined_text)\n",
        "\n",
        "    # Print confirmation for the saved file\n",
        "    print(f\"Saved: {combined_filename}\")\n",
        "\n",
        "    # Increment the counter for the next combined chunk\n",
        "    chunk_counter += 1\n",
        "\n"
      ],
      "metadata": {
        "id": "8iG8l7Heo_oc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98c25a51-c19d-4ad1-a796-8ad55771d2d8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: combined_chunk_0000.mp3\n",
            "Saved: combined_chunk_0001.mp3\n",
            "Saved: combined_chunk_0002.mp3\n",
            "Saved: combined_chunk_0003.mp3\n",
            "Saved: combined_chunk_0004.mp3\n",
            "Saved: combined_chunk_0005.mp3\n",
            "Saved: combined_chunk_0006.mp3\n",
            "Saved: combined_chunk_0007.mp3\n",
            "Saved: combined_chunk_0008.mp3\n",
            "Saved: combined_chunk_0009.mp3\n",
            "Saved: combined_chunk_0010.mp3\n",
            "Saved: combined_chunk_0011.mp3\n",
            "Saved: combined_chunk_0012.mp3\n",
            "Saved: combined_chunk_0013.mp3\n",
            "Saved: combined_chunk_0014.mp3\n",
            "Saved: combined_chunk_0015.mp3\n",
            "Saved: combined_chunk_0016.mp3\n",
            "Saved: combined_chunk_0017.mp3\n",
            "Saved: combined_chunk_0018.mp3\n",
            "Saved: combined_chunk_0019.mp3\n",
            "Saved: combined_chunk_0020.mp3\n",
            "Saved: combined_chunk_0021.mp3\n",
            "Saved: combined_chunk_0022.mp3\n",
            "Saved: combined_chunk_0023.mp3\n",
            "Saved: combined_chunk_0024.mp3\n",
            "Saved: combined_chunk_0025.mp3\n",
            "Saved: combined_chunk_0026.mp3\n",
            "Saved: combined_chunk_0027.mp3\n",
            "Saved: combined_chunk_0028.mp3\n",
            "Saved: combined_chunk_0029.mp3\n",
            "Saved: combined_chunk_0030.mp3\n",
            "Saved: combined_chunk_0031.mp3\n",
            "Saved: combined_chunk_0032.mp3\n",
            "Saved: combined_chunk_0033.mp3\n",
            "Saved: combined_chunk_0034.mp3\n",
            "Saved: combined_chunk_0035.mp3\n",
            "Saved: combined_chunk_0036.mp3\n",
            "Saved: combined_chunk_0037.mp3\n",
            "Saved: combined_chunk_0038.mp3\n",
            "Saved: combined_chunk_0039.mp3\n",
            "Saved: combined_chunk_0040.mp3\n",
            "Saved: combined_chunk_0041.mp3\n",
            "Saved: combined_chunk_0042.mp3\n",
            "Saved: combined_chunk_0043.mp3\n",
            "Saved: combined_chunk_0044.mp3\n",
            "Saved: combined_chunk_0045.mp3\n",
            "Saved: combined_chunk_0046.mp3\n",
            "Saved: combined_chunk_0047.mp3\n",
            "Saved: combined_chunk_0048.mp3\n",
            "Saved: combined_chunk_0049.mp3\n",
            "Saved: combined_chunk_0050.mp3\n",
            "Saved: combined_chunk_0051.mp3\n",
            "Saved: combined_chunk_0052.mp3\n",
            "Saved: combined_chunk_0053.mp3\n",
            "Saved: combined_chunk_0054.mp3\n",
            "Saved: combined_chunk_0055.mp3\n",
            "Saved: combined_chunk_0056.mp3\n",
            "Saved: combined_chunk_0057.mp3\n",
            "Saved: combined_chunk_0058.mp3\n",
            "Saved: combined_chunk_0059.mp3\n",
            "Saved: combined_chunk_0060.mp3\n",
            "Saved: combined_chunk_0061.mp3\n",
            "Saved: combined_chunk_0062.mp3\n",
            "Saved: combined_chunk_0063.mp3\n",
            "Saved: combined_chunk_0064.mp3\n",
            "Saved: combined_chunk_0065.mp3\n",
            "Saved: combined_chunk_0066.mp3\n",
            "Saved: combined_chunk_0067.mp3\n",
            "Saved: combined_chunk_0068.mp3\n",
            "Saved: combined_chunk_0069.mp3\n",
            "Saved: combined_chunk_0070.mp3\n",
            "Saved: combined_chunk_0071.mp3\n",
            "Saved: combined_chunk_0072.mp3\n",
            "Saved: combined_chunk_0073.mp3\n",
            "Saved: combined_chunk_0074.mp3\n",
            "Saved: combined_chunk_0075.mp3\n",
            "Saved: combined_chunk_0076.mp3\n",
            "Saved: combined_chunk_0077.mp3\n",
            "Saved: combined_chunk_0078.mp3\n",
            "Saved: combined_chunk_0079.mp3\n",
            "Saved: combined_chunk_0080.mp3\n",
            "Saved: combined_chunk_0081.mp3\n",
            "Saved: combined_chunk_0082.mp3\n",
            "Saved: combined_chunk_0083.mp3\n",
            "Saved: combined_chunk_0084.mp3\n",
            "Saved: combined_chunk_0085.mp3\n",
            "Saved: combined_chunk_0086.mp3\n",
            "Saved: combined_chunk_0087.mp3\n",
            "Saved: combined_chunk_0088.mp3\n",
            "Saved: combined_chunk_0089.mp3\n",
            "Saved: combined_chunk_0090.mp3\n",
            "Saved: combined_chunk_0091.mp3\n",
            "Saved: combined_chunk_0092.mp3\n",
            "Saved: combined_chunk_0093.mp3\n",
            "Saved: combined_chunk_0094.mp3\n",
            "Saved: combined_chunk_0095.mp3\n",
            "Saved: combined_chunk_0096.mp3\n",
            "Saved: combined_chunk_0097.mp3\n",
            "Saved: combined_chunk_0098.mp3\n",
            "Saved: combined_chunk_0099.mp3\n",
            "Saved: combined_chunk_0100.mp3\n",
            "Saved: combined_chunk_0101.mp3\n",
            "Saved: combined_chunk_0102.mp3\n",
            "Saved: combined_chunk_0103.mp3\n",
            "Saved: combined_chunk_0104.mp3\n",
            "Saved: combined_chunk_0105.mp3\n",
            "Saved: combined_chunk_0106.mp3\n",
            "Saved: combined_chunk_0107.mp3\n",
            "Saved: combined_chunk_0108.mp3\n",
            "Saved: combined_chunk_0109.mp3\n",
            "Saved: combined_chunk_0110.mp3\n",
            "Saved: combined_chunk_0111.mp3\n",
            "Saved: combined_chunk_0112.mp3\n",
            "Saved: combined_chunk_0113.mp3\n",
            "Saved: combined_chunk_0114.mp3\n",
            "Saved: combined_chunk_0115.mp3\n",
            "Saved: combined_chunk_0116.mp3\n",
            "Saved: combined_chunk_0117.mp3\n",
            "Saved: combined_chunk_0118.mp3\n",
            "Saved: combined_chunk_0119.mp3\n",
            "Saved: combined_chunk_0120.mp3\n",
            "Saved: combined_chunk_0121.mp3\n",
            "Saved: combined_chunk_0122.mp3\n",
            "Saved: combined_chunk_0123.mp3\n",
            "Saved: combined_chunk_0124.mp3\n",
            "Saved: combined_chunk_0125.mp3\n",
            "Saved: combined_chunk_0126.mp3\n",
            "Saved: combined_chunk_0127.mp3\n",
            "Saved: combined_chunk_0128.mp3\n",
            "Saved: combined_chunk_0129.mp3\n",
            "Saved: combined_chunk_0130.mp3\n",
            "Saved: combined_chunk_0131.mp3\n",
            "Saved: combined_chunk_0132.mp3\n",
            "Saved: combined_chunk_0133.mp3\n",
            "Saved: combined_chunk_0134.mp3\n",
            "Saved: combined_chunk_0135.mp3\n",
            "Saved: combined_chunk_0136.mp3\n",
            "Saved: combined_chunk_0137.mp3\n",
            "Saved: combined_chunk_0138.mp3\n",
            "Saved: combined_chunk_0139.mp3\n",
            "Saved: combined_chunk_0140.mp3\n",
            "Saved: combined_chunk_0141.mp3\n",
            "Saved: combined_chunk_0142.mp3\n",
            "Saved: combined_chunk_0143.mp3\n",
            "Saved: combined_chunk_0144.mp3\n",
            "Saved: combined_chunk_0145.mp3\n",
            "Saved: combined_chunk_0146.mp3\n",
            "Saved: combined_chunk_0147.mp3\n",
            "Saved: combined_chunk_0148.mp3\n",
            "Saved: combined_chunk_0149.mp3\n",
            "Saved: combined_chunk_0150.mp3\n",
            "Saved: combined_chunk_0151.mp3\n",
            "Saved: combined_chunk_0152.mp3\n",
            "Saved: combined_chunk_0153.mp3\n",
            "Saved: combined_chunk_0154.mp3\n",
            "Saved: combined_chunk_0155.mp3\n",
            "Saved: combined_chunk_0156.mp3\n",
            "Saved: combined_chunk_0157.mp3\n",
            "Saved: combined_chunk_0158.mp3\n",
            "Saved: combined_chunk_0159.mp3\n",
            "Saved: combined_chunk_0160.mp3\n",
            "Saved: combined_chunk_0161.mp3\n",
            "Saved: combined_chunk_0162.mp3\n",
            "Saved: combined_chunk_0163.mp3\n",
            "Saved: combined_chunk_0164.mp3\n",
            "Saved: combined_chunk_0165.mp3\n",
            "Saved: combined_chunk_0166.mp3\n",
            "Saved: combined_chunk_0167.mp3\n",
            "Saved: combined_chunk_0168.mp3\n",
            "Saved: combined_chunk_0169.mp3\n",
            "Saved: combined_chunk_0170.mp3\n",
            "Saved: combined_chunk_0171.mp3\n",
            "Saved: combined_chunk_0172.mp3\n",
            "Saved: combined_chunk_0173.mp3\n",
            "Saved: combined_chunk_0174.mp3\n",
            "Saved: combined_chunk_0175.mp3\n",
            "Saved: combined_chunk_0176.mp3\n",
            "Saved: combined_chunk_0177.mp3\n",
            "Saved: combined_chunk_0178.mp3\n",
            "Saved: combined_chunk_0179.mp3\n",
            "Saved: combined_chunk_0180.mp3\n",
            "Saved: combined_chunk_0181.mp3\n",
            "Saved: combined_chunk_0182.mp3\n",
            "Saved: combined_chunk_0183.mp3\n",
            "Saved: combined_chunk_0184.mp3\n",
            "Saved: combined_chunk_0185.mp3\n",
            "Saved: combined_chunk_0186.mp3\n",
            "Saved: combined_chunk_0187.mp3\n",
            "Saved: combined_chunk_0188.mp3\n",
            "Saved: combined_chunk_0189.mp3\n",
            "Saved: combined_chunk_0190.mp3\n",
            "Saved: combined_chunk_0191.mp3\n",
            "Saved: combined_chunk_0192.mp3\n",
            "Saved: combined_chunk_0193.mp3\n",
            "Saved: combined_chunk_0194.mp3\n",
            "Saved: combined_chunk_0195.mp3\n",
            "Saved: combined_chunk_0196.mp3\n",
            "Saved: combined_chunk_0197.mp3\n",
            "Saved: combined_chunk_0198.mp3\n",
            "Saved: combined_chunk_0199.mp3\n",
            "Saved: combined_chunk_0200.mp3\n",
            "Saved: combined_chunk_0201.mp3\n",
            "Saved: combined_chunk_0202.mp3\n",
            "Saved: combined_chunk_0203.mp3\n",
            "Saved: combined_chunk_0204.mp3\n",
            "Saved: combined_chunk_0205.mp3\n",
            "Saved: combined_chunk_0206.mp3\n",
            "Saved: combined_chunk_0207.mp3\n",
            "Saved: combined_chunk_0208.mp3\n",
            "Saved: combined_chunk_0209.mp3\n",
            "Saved: combined_chunk_0210.mp3\n",
            "Saved: combined_chunk_0211.mp3\n",
            "Saved: combined_chunk_0212.mp3\n",
            "Saved: combined_chunk_0213.mp3\n",
            "Saved: combined_chunk_0214.mp3\n",
            "Saved: combined_chunk_0215.mp3\n",
            "Saved: combined_chunk_0216.mp3\n",
            "Saved: combined_chunk_0217.mp3\n",
            "Saved: combined_chunk_0218.mp3\n",
            "Saved: combined_chunk_0219.mp3\n",
            "Saved: combined_chunk_0220.mp3\n",
            "Saved: combined_chunk_0221.mp3\n",
            "Saved: combined_chunk_0222.mp3\n",
            "Saved: combined_chunk_0223.mp3\n",
            "Saved: combined_chunk_0224.mp3\n",
            "Saved: combined_chunk_0225.mp3\n",
            "Saved: combined_chunk_0226.mp3\n",
            "Saved: combined_chunk_0227.mp3\n",
            "Saved: combined_chunk_0228.mp3\n",
            "Saved: combined_chunk_0229.mp3\n",
            "Saved: combined_chunk_0230.mp3\n",
            "Saved: combined_chunk_0231.mp3\n",
            "Saved: combined_chunk_0232.mp3\n",
            "Saved: combined_chunk_0233.mp3\n",
            "Saved: combined_chunk_0234.mp3\n",
            "Saved: combined_chunk_0235.mp3\n",
            "Saved: combined_chunk_0236.mp3\n",
            "Saved: combined_chunk_0237.mp3\n",
            "Saved: combined_chunk_0238.mp3\n",
            "Saved: combined_chunk_0239.mp3\n",
            "Saved: combined_chunk_0240.mp3\n",
            "Saved: combined_chunk_0241.mp3\n",
            "Saved: combined_chunk_0242.mp3\n",
            "Saved: combined_chunk_0243.mp3\n",
            "Saved: combined_chunk_0244.mp3\n",
            "Saved: combined_chunk_0245.mp3\n",
            "Saved: combined_chunk_0246.mp3\n",
            "Saved: combined_chunk_0247.mp3\n",
            "Saved: combined_chunk_0248.mp3\n",
            "Saved: combined_chunk_0249.mp3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "def get_translation_breakdown(chinese_sentence: str) -> str:\n",
        "    # Initialize the OpenAI client with your API key\n",
        "    client = OpenAI(\n",
        "        api_key=\"xai-dXIGonbjZNs90ph3MeXiqSC6MkUJ3foBgKM2HxzyQMFcrN6T8rrCXWamlSIJsZ6LuFpD67rh6e76vm9J\",\n",
        "        base_url=\"https://api.x.ai/v1\",\n",
        "    )\n",
        "\n",
        "    # Define the prompt with placeholders for the user input\n",
        "    prompt = f'''\n",
        "    \"Given the following Chinese sentence, provide the English translation, a breakdown of the words (with each word's Chinese form, pinyin, and its translation), and a list of pinyin for each word in the sentence:\n",
        "\n",
        "    Input: {chinese_sentence}\n",
        "\n",
        "    Output:\n",
        "\n",
        "    English translation of the sentence\n",
        "\n",
        "    A breakdown of each word in the sentence:\n",
        "\n",
        "    Word in Chinese: (pinyin) [Translation]\n",
        "\n",
        "    Pinyin for the whole sentence.\n",
        "\n",
        "    In addition dont add bold or italic formatting. Just do proper content structure formatting like newline.\n",
        "    \"\n",
        "    '''\n",
        "\n",
        "    # Request completion from the AI model\n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"grok-3-beta\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": prompt},\n",
        "            {\"role\": \"user\", \"content\": chinese_sentence},\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    # Return the result from the AI model\n",
        "    return completion.choices[0].message.content\n",
        "\n",
        "# Example usage:\n",
        "chinese_input = \"不知道小伙伴们的选择题做对了几道呢所以你可以很明显地看到每5到10年\"\n",
        "result = get_translation_breakdown(chinese_input)\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "Nx3QwFP_lmKK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a535fc3b-cf6d-4d4e-f700-12a0d05a1801"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.75.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (2.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
            "English translation of the sentence:\n",
            "I don’t know how many multiple-choice questions the little friends got right, so you can clearly see every 5 to 10 years.\n",
            "\n",
            "A breakdown of each word in the sentence:\n",
            "\n",
            "Word in Chinese: 不知道 (bù zhīdào) [don’t know]\n",
            "Word in Chinese: 小伙伴们 (xiǎo huǒbànmen) [little friends/partners]\n",
            "Word in Chinese: 的 (de) [possessive particle, of]\n",
            "Word in Chinese: 选择题 (xuǎnzé tí) [multiple-choice questions]\n",
            "Word in Chinese: 做对 (zuò duì) [got right/correct]\n",
            "Word in Chinese: 了 (le) [particle indicating completed action]\n",
            "Word in Chinese: 几道 (jī dào) [how many (questions)]\n",
            "Word in Chinese: 呢 (ne) [particle for question or emphasis]\n",
            "Word in Chinese: 所以 (suǒyǐ) [so/therefore]\n",
            "Word in Chinese: 你 (nǐ) [you]\n",
            "Word in Chinese: 可以 (kěyǐ) [can]\n",
            "Word in Chinese: 很 (hěn) [very]\n",
            "Word in Chinese: 明显地 (míngxiǎn de) [clearly/obviously]\n",
            "Word in Chinese: 看到 (kàndào) [see]\n",
            "Word in Chinese: 每 (měi) [every]\n",
            "Word in Chinese: 5到10年 (5 dào 10 nián) [5 to 10 years]\n",
            "\n",
            "Pinyin for the whole sentence:\n",
            "bù zhīdào xiǎo huǒbànmen de xuǎnzé tí zuò duì le jī dào ne suǒyǐ nǐ kěyǐ hěn míngxiǎn de kàndào měi 5 dào 10 nián\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "from googletrans import Translator\n",
        "import jieba  # Import jieba for Chinese word segmentation\n",
        "import time\n",
        "# Directory where your text files are stored\n",
        "output_dir = \"/content/split_audio\"  # Update with the correct path\n",
        "\n",
        "# Initialize Google Translate API (googletrans library)\n",
        "translator = Translator()\n",
        "sleep_duration = 0.2\n",
        "# Function to translate a word using Google Translate API\n",
        "def translate_word(word):\n",
        "    time.sleep(sleep_duration)\n",
        "    try:\n",
        "        translated = translator.translate(word, src='zh-cn', dest='en')\n",
        "        if translated.text:\n",
        "            return translated.text\n",
        "        else:\n",
        "            print(f\"Warning: No translation for {word}\")\n",
        "            return f\"No translation for {word}\"\n",
        "    except Exception as e:\n",
        "        print(f\"Error translating {word}: {e}\")\n",
        "        return f\"Translation error for {word}\"\n",
        "\n",
        "\n",
        "\n",
        "# Function to get Pinyin of a Chinese word using pypinyin\n",
        "def get_pinyin(word):\n",
        "    from pypinyin import lazy_pinyin  # Import here to avoid unnecessary import if not used\n",
        "    pinyin = lazy_pinyin(word)  # Convert the word to Pinyin\n",
        "    return ' '.join(pinyin)  # Join the list into a string\n",
        "\n",
        "# Function to process all .txt files and generate word meanings\n",
        "def process_text_files():\n",
        "    for filename in os.listdir(output_dir):\n",
        "        if filename.endswith(\".txt\"):\n",
        "            file_path = os.path.join(output_dir, filename)\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                sentence = f.read().strip()  # Read sentence from the file\n",
        "                sentence_translation =  translate_word(sentence)\n",
        "                # Use jieba to segment the sentence into words\n",
        "                words = jieba.lcut(sentence)  # lcut() returns a list of words\n",
        "\n",
        "                # For each word in the sentence, translate or look up its meaning\n",
        "                word_meanings = {}\n",
        "                for word in words:\n",
        "                    meaning = translate_word(word)  # Get the English translation\n",
        "\n",
        "                    pinyin = get_pinyin(word)  # Get the Pinyin for the word\n",
        "                    if meaning:\n",
        "                        word_meanings[word] = {'meaning': meaning, 'pinyin': pinyin}\n",
        "\n",
        "                # Prepare the formatted output\n",
        "                formatted_output = f\"Sentence: {sentence}\\n\"\n",
        "                formatted_output += f\"Translation: {sentence_translation}\\n\\n\"\n",
        "                for word, info in word_meanings.items():\n",
        "                    formatted_output += f\"{word}: [{info['meaning']}] ({info['pinyin']})\\n\"\n",
        "\n",
        "                print(formatted_output)\n",
        "\n",
        "                # Save the formatted output back to the same file\n",
        "                # with open(file_path, 'w', encoding='utf-8') as txt_file:\n",
        "                #     txt_file.write(formatted_output)\n",
        "\n",
        "                # Print confirmation for the saved file\n",
        "                print(f\"Formatted output saved in: {filename}\")\n",
        "\n",
        "# Call the function to process the text files\n",
        "process_text_files()\n"
      ],
      "metadata": {
        "id": "xtw6_EPO3ib8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import genanki\n",
        "import os\n",
        "import time\n",
        "from googletrans import Translator\n",
        "import jieba\n",
        "from pypinyin import lazy_pinyin  # For getting pinyin\n",
        "\n",
        "# Directory where your text files are stored\n",
        "output_dir = \"/content/split_audio\"  # Update with the correct path\n",
        "\n",
        "# Initialize Google Translate API (googletrans library)\n",
        "translator = Translator()\n",
        "\n",
        "# Audio file directory (where MP3 files are stored)\n",
        "audio_dir = \"/content/split_audio\"  # Update with your directory for MP3 files\n",
        "\n",
        "# Anki Deck Settings\n",
        "deck_name = \"Chinese Learning Deck\"\n",
        "deck_id = 1234567890  # Unique identifier for your deck (must be an integer)\n",
        "\n",
        "# Function to get Pinyin of a Chinese word using pypinyin\n",
        "def get_pinyin(word):\n",
        "    pinyin = lazy_pinyin(word)  # Convert the word to Pinyin\n",
        "    return ' '.join(pinyin)  # Join the list into a string\n",
        "\n",
        "# Function to translate a word using Google Translate API\n",
        "def translate_word(word):\n",
        "    try:\n",
        "        translated = translator.translate(word, src='zh-cn', dest='en')\n",
        "        return translated.text\n",
        "    except Exception as e:\n",
        "        print(f\"Error translating {word}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Function to create Anki card front and back\n",
        "def create_anki_cards(sentence, sentence_translation, word_meanings, audio_filename):\n",
        "    # Create the front of the card\n",
        "    front = f\"Text: {sentence}<br>Audio: [sound:{audio_filename}]\"\n",
        "\n",
        "    # Prepare the breakdown for the back of the card\n",
        "    breakdown = \"\"\n",
        "    for word, info in word_meanings.items():\n",
        "        breakdown += f\"{word}: [{info['meaning']}] ({info['pinyin']})<br>\"\n",
        "\n",
        "    # Create the back of the card\n",
        "    back = f\"Translation: {sentence_translation}<br>Audio: [sound:{audio_filename}]<br>Breakdown: {breakdown}\"\n",
        "\n",
        "    return front, back\n",
        "# Function to create Anki card front and back\n",
        "def create_anki_cards(sentence, sentence_translation, word_meanings, audio_filename):\n",
        "    # Create the front of the card\n",
        "    front = f\"Text: {sentence}<br>Audio: [sound:{audio_filename}]\"\n",
        "\n",
        "    # Prepare the breakdown for the back of the card\n",
        "    breakdown = \"\"\n",
        "    for word, info in word_meanings.items():\n",
        "        breakdown += f\"{word}: [{info['meaning']}] ({info['pinyin']})<br>\"\n",
        "\n",
        "    # Convert newlines in sentence_translation to <br> to preserve HTML formatting\n",
        "    sentence_translation = sentence_translation.replace(\"\\n\", \"<br>\")\n",
        "\n",
        "    # Create the back of the card\n",
        "    back = f\"Translation: {sentence_translation}<br>Audio: [sound:{audio_filename}]<br>Breakdown:<br>{breakdown}\"\n",
        "\n",
        "    return front, back\n",
        "\n",
        "# Create the Anki deck\n",
        "def create_anki_deck_():\n",
        "    my_deck = genanki.Deck(deck_id, deck_name)\n",
        "    my_model = genanki.Model(\n",
        "        1607392319,\n",
        "        'Basic Model with Audio',\n",
        "        fields=[\n",
        "            {'name': 'Front'},\n",
        "            {'name': 'Back'},\n",
        "        ],\n",
        "        templates=[\n",
        "            {\n",
        "                'name': 'Card 1',\n",
        "                'qfmt': '{{Front}}',\n",
        "                'afmt': '{{Back}}',\n",
        "            },\n",
        "        ],\n",
        "        css=\"\"\"\n",
        "        .card {\n",
        "            font-family: Arial, sans-serif;\n",
        "            font-size: 20px;\n",
        "            text-align: center;\n",
        "        }\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    # Process each text file and add the corresponding cards to Anki deck\n",
        "    for filename in os.listdir(output_dir):\n",
        "        if filename.endswith(\".txt\"):\n",
        "            file_path = os.path.join(output_dir, filename)\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                sentence = f.read().strip()  # Read sentence from the file\n",
        "                sentence_translation = translate_word(sentence)\n",
        "\n",
        "                # Use jieba to segment the sentence into words\n",
        "                words = jieba.lcut(sentence)\n",
        "\n",
        "                word_meanings = {}\n",
        "                for word in words:\n",
        "                    meaning = translate_word(word)\n",
        "                    pinyin = get_pinyin(word)\n",
        "                    if meaning:\n",
        "                        word_meanings[word] = {'meaning': meaning, 'pinyin': pinyin}\n",
        "\n",
        "                # Assume the corresponding audio file is named the same as the text file (but with mp3 extension)\n",
        "                audio_filename = filename.replace(\".txt\", \".mp3\")\n",
        "                audio_filepath = os.path.join(audio_dir, audio_filename)\n",
        "\n",
        "                # Check if the audio file exists\n",
        "                if os.path.exists(audio_filepath):\n",
        "                  # Create front and back for Anki card\n",
        "                  front, back = create_anki_cards(sentence, sentence_translation, word_meanings, audio_filename)\n",
        "\n",
        "                  # Create an Anki note (card) and add it to the deck\n",
        "                  my_note = genanki.Note(\n",
        "                      model=my_model,\n",
        "                      fields=[front, back],\n",
        "                      tags=[\"Chinese_Learning\"]\n",
        "                  )\n",
        "                  my_deck.add_note(my_note)\n",
        "                else:\n",
        "                  print(\"Audio file does not exist\")\n",
        "\n",
        "    # Save the deck to a file\n",
        "    genanki.Package(my_deck).write_to_file(\"/content/Chinese_Learning_Deck.apkg\")\n",
        "    print(\"Deck created successfully!\")\n",
        "\n",
        "# Call the function to create the Anki deck\n",
        "create_anki_deck()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lETCeoKuD9Dp",
        "outputId": "69934bb8-9d97-41a3-f6a4-77286475ccce"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deck created successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import genanki\n",
        "import os\n",
        "import time\n",
        "from googletrans import Translator\n",
        "import jieba\n",
        "import time\n",
        "from pypinyin import lazy_pinyin  # For getting pinyin\n",
        "\n",
        "# Directory where your text files are stored\n",
        "output_dir = \"/content/split_audio\"  # Update with the correct path\n",
        "\n",
        "# Initialize Google Translate API (googletrans library)\n",
        "translator = Translator()\n",
        "\n",
        "# Audio file directory (where MP3 files are stored)\n",
        "audio_dir = \"/content/split_audio\"  # Update with your directory for MP3 files\n",
        "\n",
        "# Anki Deck Settings\n",
        "deck_name = \"Chinese Learning Deck\"\n",
        "deck_id = 1234567890  # Unique identifier for your deck (must be an integer)\n",
        "\n",
        "# Function to get Pinyin of a Chinese word using pypinyin\n",
        "def get_pinyin(word):\n",
        "    pinyin = lazy_pinyin(word)  # Convert the word to Pinyin\n",
        "    return ' '.join(pinyin)  # Join the list into a string\n",
        "\n",
        "# Function to translate a word using Google Translate API\n",
        "def translate_word(word):\n",
        "    time.sleep(0.2)\n",
        "    try:\n",
        "        translated = translator.translate(word, src='zh-cn', dest='en')\n",
        "        return translated.text\n",
        "    except Exception as e:\n",
        "        print(f\"Error translating {word}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Function to create Anki card front and back\n",
        "def create_anki_cards(sentence, sentence_translation, word_meanings, audio_filename):\n",
        "    # Create the front of the card\n",
        "    front = f\"Text: {sentence}<br>Audio: [sound:{audio_filename}]\"\n",
        "\n",
        "    # Prepare the breakdown for the back of the card\n",
        "    breakdown = \"\"\n",
        "    for word, info in word_meanings.items():\n",
        "        breakdown += f\"{word}: [{info['meaning']}] ({info['pinyin']})<br>\"\n",
        "\n",
        "    # Create the back of the card\n",
        "    back = f\"Translation: {sentence_translation}<br>Audio: [sound:{audio_filename}]<br>Breakdown: {breakdown}\"\n",
        "\n",
        "    return front, back\n",
        "\n",
        "# Create the Anki deck\n",
        "def create_anki_deck():\n",
        "    my_deck = genanki.Deck(deck_id, deck_name)\n",
        "    my_model = genanki.Model(\n",
        "        1607392319,\n",
        "        'Basic Model with Audio',\n",
        "        fields=[\n",
        "            {'name': 'Front'},\n",
        "            {'name': 'Back'},\n",
        "        ],\n",
        "        templates=[\n",
        "            {\n",
        "                'name': 'Card 1',\n",
        "                'qfmt': '{{Front}}',\n",
        "                'afmt': '{{Back}}',\n",
        "            },\n",
        "        ],\n",
        "        css=\"\"\"\n",
        "        .card {\n",
        "            font-family: Arial, sans-serif;\n",
        "            font-size: 20px;\n",
        "            text-align: center;\n",
        "        }\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    # List to store audio files for inclusion in the package\n",
        "    audio_files = []\n",
        "\n",
        "    # Process each text file and add the corresponding cards to Anki deck\n",
        "    for filename in os.listdir(output_dir):\n",
        "        if filename.endswith(\".txt\"):\n",
        "            file_path = os.path.join(output_dir, filename)\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                sentence = f.read().strip()  # Read sentence from the file\n",
        "                sentence_translation = translate_word(sentence)\n",
        "\n",
        "                # Use jieba to segment the sentence into words\n",
        "                words = jieba.lcut(sentence)\n",
        "\n",
        "                word_meanings = {}\n",
        "                for word in words:\n",
        "                    meaning = translate_word(word)\n",
        "                    pinyin = get_pinyin(word)\n",
        "                    if meaning:\n",
        "                        word_meanings[word] = {'meaning': meaning, 'pinyin': pinyin}\n",
        "\n",
        "                # Assume the corresponding audio file is named the same as the text file (but with mp3 extension)\n",
        "                audio_filename = filename.replace(\".txt\", \".mp3\")\n",
        "                audio_filepath = os.path.join(audio_dir, audio_filename)\n",
        "\n",
        "                # Check if the audio file exists\n",
        "                if os.path.exists(audio_filepath):\n",
        "                    # Add audio file to the list of media files\n",
        "                    audio_files.append(audio_filepath)\n",
        "\n",
        "                    # Create front and back for Anki card if the audio file exists\n",
        "                    front, back = create_anki_cards(sentence, sentence_translation, word_meanings, audio_filename)\n",
        "\n",
        "                    # Create an Anki note (card) and add it to the deck\n",
        "                    my_note = genanki.Note(\n",
        "                        model=my_model,\n",
        "                        fields=[front, back],\n",
        "                        tags=[\"Chinese_Learning\"]\n",
        "                    )\n",
        "                    my_deck.add_note(my_note)\n",
        "                else:\n",
        "                    print(f\"Warning: Audio file '{audio_filename}' not found for sentence: {sentence}\")\n",
        "\n",
        "    # Add audio files to the package\n",
        "    my_package = genanki.Package(my_deck)\n",
        "    my_package.media_files = audio_files\n",
        "\n",
        "    # Save the deck to a file\n",
        "    my_package.write_to_file(\"/content/Chinese_Learning_Deck_with_audio.apkg\")\n",
        "    print(\"Deck created successfully with audio!\")\n",
        "\n",
        "# Call the function to create the Anki deck\n",
        "create_anki_deck()\n"
      ],
      "metadata": {
        "id": "8lAda5trKKgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import genanki\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "# Directory where your text files are stored\n",
        "output_dir = \"/content/split_audio\"  # Update with the correct path\n",
        "\n",
        "# Audio file directory (where MP3 files are stored)\n",
        "audio_dir = \"/content/split_audio\"  # Update with your directory for MP3 files\n",
        "\n",
        "# Anki Deck Settings\n",
        "deck_name = \"Chinese Learning Deck\"\n",
        "deck_id = 1234567890  # Unique identifier for your deck (must be an integer)\n",
        "\n",
        "# Initialize OpenAI client\n",
        "client = OpenAI(\n",
        "    api_key=\"xai-dXIGonbjZNs90ph3MeXiqSC6MkUJ3foBgKM2HxzyQMFcrN6T8rrCXWamlSIJsZ6LuFpD67rh6e76vm9J\",\n",
        "    base_url=\"https://api.x.ai/v1\",\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Function to create Anki card front and back\n",
        "def create_anki_cards(sentence, sentence_translation, word_meanings, audio_filename):\n",
        "    # Create the front of the card\n",
        "    front = f\"Text: {sentence}<br>Audio: [sound:{audio_filename}]\"\n",
        "\n",
        "    # Prepare the breakdown for the back of the card\n",
        "    breakdown = \"\"\n",
        "    for word, info in word_meanings.items():\n",
        "        breakdown += f\"{word}: [{info['meaning']}] ({info['pinyin']})<br>\"\n",
        "\n",
        "    # Create the back of the card\n",
        "    back = f\"Translation: {sentence_translation}<br>Audio: [sound:{audio_filename}]<br>Breakdown: {breakdown}\"\n",
        "\n",
        "    return front, back\n",
        "\n",
        "# Create the Anki deck\n",
        "def create_anki_deck():\n",
        "    my_deck = genanki.Deck(deck_id, deck_name)\n",
        "    my_model = genanki.Model(\n",
        "        1607392319,\n",
        "        'Basic Model with Audio',\n",
        "        fields=[\n",
        "            {'name': 'Front'},\n",
        "            {'name': 'Back'},\n",
        "        ],\n",
        "        templates=[\n",
        "            {\n",
        "                'name': 'Card 1',\n",
        "                'qfmt': '{{Front}}',\n",
        "                'afmt': '{{Back}}',\n",
        "            },\n",
        "        ],\n",
        "        css=\"\"\"\n",
        "        .card {\n",
        "            font-family: Arial, sans-serif;\n",
        "            font-size: 20px;\n",
        "            text-align: center;\n",
        "        }\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    # Process each text file and add the corresponding cards to Anki deck\n",
        "    for filename in os.listdir(output_dir):\n",
        "        if filename.endswith(\".txt\"):\n",
        "            file_path = os.path.join(output_dir, filename)\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                sentence = f.read().strip()  # Read sentence from the file\n",
        "\n",
        "                # Use OpenAI to get translation, breakdown, and pinyin\n",
        "                sentence_translation_and_breakdown = get_translation_breakdown(sentence)\n",
        "\n",
        "                # The output from OpenAI will directly give us the structure we need\n",
        "                # We can directly use the AI model's output without any additional reformatting\n",
        "\n",
        "                # The sentence_translation_and_breakdown contains both the translation and the word breakdown\n",
        "                sentence_translation = sentence_translation_and_breakdown  # No need to process it further\n",
        "\n",
        "                # Assume the corresponding audio file is named the same as the text file (but with mp3 extension)\n",
        "                audio_filename = filename.replace(\".txt\", \".mp3\")\n",
        "                audio_filepath = os.path.join(audio_dir, audio_filename)\n",
        "\n",
        "                # Check if the audio file exists\n",
        "                if os.path.exists(audio_filepath):\n",
        "                    # Create front and back for Anki card\n",
        "                    front, back = create_anki_cards(sentence, sentence_translation, {}, audio_filename)\n",
        "                    print(front)\n",
        "                    print(back)\n",
        "                    # Create an Anki note (card) and add it to the deck\n",
        "                    my_note = genanki.Note(\n",
        "                        model=my_model,\n",
        "                        fields=[front, back],\n",
        "                        tags=[\"Chinese_Learning\"]\n",
        "                    )\n",
        "                    my_deck.add_note(my_note)\n",
        "                else:\n",
        "                    print(\"Audio file does not exist\")\n",
        "\n",
        "    # Save the deck to a file\n",
        "    genanki.Package(my_deck).write_to_file(\"/content/Chinese_Learning_Deck.apkg\")\n",
        "    print(\"Deck created successfully!\")\n",
        "\n",
        "# Call the function to create the Anki deck\n",
        "create_anki_deck()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mqcgks9UBIm8",
        "outputId": "983a00fa-2198-4e92-b1c9-47254e0c6177"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: 而是站在历史的高度这么一窥探你就能看到全球经济背后的一个一个潮流<br>Audio: [sound:combined_chunk_0004.mp3]\n",
            "Translation: English translation of the sentence:\n",
            "Instead, standing at the height of history, with just a glimpse, you can see the trends behind the global economy one by one.\n",
            "\n",
            "A breakdown of each word in the sentence:\n",
            "- 而是 (ér shì) [instead]\n",
            "- 站 (zhàn) [stand]\n",
            "- 在 (zài) [at/in/on]\n",
            "- 历史 (lì shǐ) [history]\n",
            "- 的 (de) [of/possessive particle]\n",
            "- 高度 (gāo dù) [height/level]\n",
            "- 这么 (zhè me) [this way/so]\n",
            "- 一 (yī) [one/a]\n",
            "- 窥探 (kuī tàn) [peek/glimpse/explore]\n",
            "- 你 (nǐ) [you]\n",
            "- 就 (jiù) [then/just]\n",
            "- 能 (néng) [can/able to]\n",
            "- 看到 (kàn dào) [see]\n",
            "- 全球 (quán qiú) [global]\n",
            "- 经济 (jīng jì) [economy]\n",
            "- 背后 (bèi hòu) [behind]\n",
            "- 的 (de) [of/possessive particle]\n",
            "- 一个一个 (yī gè yī gè) [one by one]\n",
            "- 潮流 (cháo liú) [trend/tide]\n",
            "\n",
            "Pinyin for the whole sentence:\n",
            "ér shì zhàn zài lì shǐ de gāo dù zhè me yī kuī tàn nǐ jiù néng kàn dào quán qiú jīng jì bèi hòu de yī gè yī gè cháo liú<br>Audio: [sound:combined_chunk_0004.mp3]<br>Breakdown: \n",
            "Text: 就是一家公司它市值雄霸天下的一个时代而且我觉得挺有意思的是<br>Audio: [sound:combined_chunk_0002.mp3]\n",
            "Translation: English translation of the sentence:\n",
            "It is an era in which a company dominates the world with its market value, and I think it is quite interesting that...\n",
            "\n",
            "A breakdown of each word in the sentence:\n",
            "- 就是 (jiùshì) [exactly is / precisely is]\n",
            "- 一家 (yījiā) [a / one (used for counting companies or families)]\n",
            "- 公司 (gōngsī) [company]\n",
            "- 它 (tā) [it]\n",
            "- 市值 (shìzhí) [market value]\n",
            "- 雄霸天下 (xióngbà tiānxià) [dominate the world]\n",
            "- 的 (de) [possessive particle / of]\n",
            "- 一个 (yīgè) [a / one (used for counting eras or items)]\n",
            "- 时代 (shídài) [era / age]\n",
            "- 而且 (érqiě) [moreover / and also]\n",
            "- 我 (wǒ) [I / me]\n",
            "- 觉得 (juéde) [feel / think]\n",
            "- 挺 (tǐng) [quite / rather]\n",
            "- 有意思 (yǒu yìsi) [interesting / meaningful]\n",
            "- 的 (de) [possessive particle / of]\n",
            "- 是 (shì) [is / to be]\n",
            "\n",
            "Pinyin for the whole sentence:\n",
            "jiùshì yījiā gōngsī tā shìzhí xióngbà tiānxià de yīgè shídài érqiě wǒ juéde tǐng yǒu yìsi de shì<br>Audio: [sound:combined_chunk_0002.mp3]<br>Breakdown: \n",
            "Text: 来咱们今天来说点轻松的咱们来看看在过去的55年里头<br>Audio: [sound:combined_chunk_0000.mp3]\n",
            "Translation: English translation of the sentence:\n",
            "Come on, let's talk about something light today, let's take a look at the past 55 years.\n",
            "\n",
            "A breakdown of each word in the sentence:\n",
            "- 来 (lái) [Come]\n",
            "- 咱们 (zánmen) [We/Us (inclusive)]\n",
            "- 今天 (jīntiān) [Today]\n",
            "- 来 (lái) [Come/Let's (used for suggestion)]\n",
            "- 说 (shuō) [Talk/Say]\n",
            "- 点 (diǎn) [Some/A bit]\n",
            "- 轻松 (qīngsōng) [Light/Easy/Relaxed]\n",
            "- 的 (de) [(possessive or descriptive particle)]\n",
            "- 咱们 (zánmen) [We/Us (inclusive)]\n",
            "- 来 (lái) [Come/Let's (used for suggestion)]\n",
            "- 看看 (kànkàn) [Take a look/See]\n",
            "- 在 (zài) [In/At]\n",
            "- 过去 (guòqù) [Past]\n",
            "- 的 (de) [(possessive or descriptive particle)]\n",
            "- 55 (wǔshíwǔ) [55]\n",
            "- 年 (nián) [Year]\n",
            "- 里头 (lǐtou) [Inside/In (often used for time periods)]\n",
            "\n",
            "Pinyin for the whole sentence:\n",
            "lái zánmen jīntiān lái shuō diǎn qīngsōng de zánmen lái kànkàn zài guòqù de wǔshíwǔ nián lǐtou<br>Audio: [sound:combined_chunk_0000.mp3]<br>Breakdown: \n",
            "Text: 一个一个时代的缩影可能对于任何一家公司来说<br>Audio: [sound:combined_chunk_0005.mp3]\n",
            "Translation: English translation of the sentence:\n",
            "A microcosm of an era may, for any company, be...\n",
            "\n",
            "Breakdown of each word in the sentence:\n",
            "- 一个 (yī gè) [one; a]\n",
            "- 一个 (yī gè) [one; a]\n",
            "- 时代 (shí dài) [era; age]\n",
            "- 的 (de) [possessive particle, often translated as \"of\"]\n",
            "- 缩影 (suō yǐng) [microcosm; miniature]\n",
            "- 可能 (kě néng) [possible; maybe]\n",
            "- 对于 (duì yú) [regarding; for]\n",
            "- 任何 (rèn hé) [any; whatever]\n",
            "- 一家 (yī jiā) [one (used for counting organizations or families); a]\n",
            "- 公司 (gōng sī) [company]\n",
            "- 来说 (lái shuō) [speaking of; in terms of]\n",
            "\n",
            "Pinyin for the whole sentence:\n",
            "yī gè yī gè shí dài de suō yǐng kě néng duì yú rèn hé yī jiā gōng sī lái shuō<br>Audio: [sound:combined_chunk_0005.mp3]<br>Breakdown: \n",
            "Text: 如果你不把这些公司看成是一个一个公司它们是一个个体<br>Audio: [sound:combined_chunk_0003.mp3]\n",
            "Translation: English translation of the sentence:\n",
            "If you don't see these companies as individual entities, they are a single entity.\n",
            "\n",
            "A breakdown of each word in the sentence:\n",
            "- 如果 (rúguǒ) [if]\n",
            "- 你 (nǐ) [you]\n",
            "- 不 (bù) [not]\n",
            "- 把 (bǎ) [a grammatical particle used to indicate the object of an action]\n",
            "- 这些 (zhèxiē) [these]\n",
            "- 公司 (gōngsī) [companies/company]\n",
            "- 看成 (kànchéng) [see as/regard as]\n",
            "- 是 (shì) [is/are]\n",
            "- 一个一个 (yī gè yī gè) [one by one/individual]\n",
            "- 公司 (gōngsī) [companies/company]\n",
            "- 它们 (tāmen) [they/them]\n",
            "- 是 (shì) [is/are]\n",
            "- 一个 (yī gè) [a/one]\n",
            "- 个体 (gètǐ) [individual/entity]\n",
            "\n",
            "Pinyin for the whole sentence:\n",
            "rúguǒ nǐ bù bǎ zhèxiē gōngsī kànchéng shì yī gè yī gè gōngsī tāmen shì yī gè gètǐ<br>Audio: [sound:combined_chunk_0003.mp3]<br>Breakdown: \n",
            "Text: 全世界那些曾经市值最高的公司一会儿你就会看到基本上每5到10年<br>Audio: [sound:combined_chunk_0001.mp3]\n",
            "Translation: English translation of the sentence:\n",
            "All over the world, those companies that were once the highest in market value, you will see in a moment, basically change every 5 to 10 years.\n",
            "\n",
            "A breakdown of each word in the sentence:\n",
            "\n",
            "Word in Chinese: 全世界 (quán shìjiè) [All over the world]\n",
            "Word in Chinese: 那些 (nàxiē) [Those]\n",
            "Word in Chinese: 曾经 (céngjīng) [Once / Ever]\n",
            "Word in Chinese: 市值 (shìzhí) [Market value]\n",
            "Word in Chinese: 最高 (zuìgāo) [Highest]\n",
            "Word in Chinese: 的 (de) [Possessive particle, often used to link attributes to nouns]\n",
            "Word in Chinese: 公司 (gōngsī) [Company / Companies]\n",
            "Word in Chinese: 一会儿 (yīhuìr) [In a moment / Shortly]\n",
            "Word in Chinese: 你 (nǐ) [You]\n",
            "Word in Chinese: 就 (jiù) [Then / Just]\n",
            "Word in Chinese: 会 (huì) [Will / Can]\n",
            "Word in Chinese: 看到 (kàndào) [See / Notice]\n",
            "Word in Chinese: 基本上 (jīběn shàng) [Basically / Fundamentally]\n",
            "Word in Chinese: 每 (měi) [Every / Each]\n",
            "Word in Chinese: 5到10年 (wǔ dào shí nián) [5 to 10 years]\n",
            "\n",
            "Pinyin for the whole sentence:\n",
            "quán shìjiè nàxiē céngjīng shìzhí zuìgāo de gōngsī yīhuìr nǐ jiù huì kàndào jīběn shàng měi wǔ dào shí nián<br>Audio: [sound:combined_chunk_0001.mp3]<br>Breakdown: \n",
            "Deck created successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Zip and download generated clips"
      ],
      "metadata": {
        "id": "MiLI7nSsrWJH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "# Specify the folder path\n",
        "folder_path = \"/content/split_audio\"\n",
        "\n",
        "# Create a zip file of the folder\n",
        "shutil.make_archive('/content/split_audio', 'zip', folder_path)\n",
        "\n",
        "# Provide a download link for the zip file\n",
        "files.download('/content/split_audio.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "jXeOtfBvpIhX",
        "outputId": "d17dc5f5-fd22-4529-e65e-02a354c25f2b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_574b8c20-1fad-41ea-bf68-5c8fb8095833\", \"split_audio.zip\", 377813)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_deck"
      ],
      "metadata": {
        "id": "A6tfMkQAqFdr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "782ae7e9-0c8a-49ca-cfff-d75d1d8b708b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'my_deck' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-c22ab90c2bfc>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmy_deck\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'my_deck' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function Documentation: remove_files_starting_from_6\n",
        "Purpose:\n",
        "The remove_files_starting_from_6 function is designed to remove files from a specified directory that follow the pattern combined_chunk_ and have chunk numbers starting from 0006 onwards. This function can be used to delete all files that match this condition, including .mp3 and .txt files."
      ],
      "metadata": {
        "id": "iD7-wq3wF40O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Directory where your files are stored\n",
        "directory = '/content/split_audio'  # Update with the correct path if needed\n",
        "\n",
        "# List all files in the directory\n",
        "files_in_directory = os.listdir(directory)\n",
        "\n",
        "# Loop through the files and remove those starting from \"combined_chunk_0006\" and onwards\n",
        "for file in files_in_directory:\n",
        "    # Check if the filename matches the pattern for chunk numbers starting from 0006\n",
        "    if file.startswith(\"combined_chunk_\"):\n",
        "        # Extract the number after 'combined_chunk_'\n",
        "        file_number = file.split('_')[2].split('.')[0]  # Extract the numeric part\n",
        "        if file_number.isdigit() and int(file_number) >= 6:\n",
        "            file_path = os.path.join(directory, file)\n",
        "            os.remove(file_path)\n",
        "            print(f\"Removed: {file_path}\")\n",
        "\n",
        "print(\"Files starting from combined_chunk_0006 and onwards have been removed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13Tl2qEDFOik",
        "outputId": "e75fff0d-829b-4ded-d556-29abc86fc76f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removed: /content/split_audio/combined_chunk_0177.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0082.txt\n",
            "Removed: /content/split_audio/combined_chunk_0133.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0072.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0204.txt\n",
            "Removed: /content/split_audio/combined_chunk_0182.txt\n",
            "Removed: /content/split_audio/combined_chunk_0235.txt\n",
            "Removed: /content/split_audio/combined_chunk_0064.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0194.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0025.txt\n",
            "Removed: /content/split_audio/combined_chunk_0220.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0192.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0236.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0124.txt\n",
            "Removed: /content/split_audio/combined_chunk_0149.txt\n",
            "Removed: /content/split_audio/combined_chunk_0016.txt\n",
            "Removed: /content/split_audio/combined_chunk_0222.txt\n",
            "Removed: /content/split_audio/combined_chunk_0148.txt\n",
            "Removed: /content/split_audio/combined_chunk_0238.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0082.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0182.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0183.txt\n",
            "Removed: /content/split_audio/combined_chunk_0070.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0209.txt\n",
            "Removed: /content/split_audio/combined_chunk_0156.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0057.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0249.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0203.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0219.txt\n",
            "Removed: /content/split_audio/combined_chunk_0055.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0062.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0200.txt\n",
            "Removed: /content/split_audio/combined_chunk_0084.txt\n",
            "Removed: /content/split_audio/combined_chunk_0203.txt\n",
            "Removed: /content/split_audio/combined_chunk_0206.txt\n",
            "Removed: /content/split_audio/combined_chunk_0232.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0214.txt\n",
            "Removed: /content/split_audio/combined_chunk_0104.txt\n",
            "Removed: /content/split_audio/combined_chunk_0049.txt\n",
            "Removed: /content/split_audio/combined_chunk_0248.txt\n",
            "Removed: /content/split_audio/combined_chunk_0106.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0066.txt\n",
            "Removed: /content/split_audio/combined_chunk_0219.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0180.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0162.txt\n",
            "Removed: /content/split_audio/combined_chunk_0029.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0248.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0193.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0063.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0243.txt\n",
            "Removed: /content/split_audio/combined_chunk_0185.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0108.txt\n",
            "Removed: /content/split_audio/combined_chunk_0197.txt\n",
            "Removed: /content/split_audio/combined_chunk_0009.txt\n",
            "Removed: /content/split_audio/combined_chunk_0146.txt\n",
            "Removed: /content/split_audio/combined_chunk_0051.txt\n",
            "Removed: /content/split_audio/combined_chunk_0067.txt\n",
            "Removed: /content/split_audio/combined_chunk_0234.txt\n",
            "Removed: /content/split_audio/combined_chunk_0241.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0026.txt\n",
            "Removed: /content/split_audio/combined_chunk_0038.txt\n",
            "Removed: /content/split_audio/combined_chunk_0089.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0097.txt\n",
            "Removed: /content/split_audio/combined_chunk_0134.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0174.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0091.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0239.txt\n",
            "Removed: /content/split_audio/combined_chunk_0079.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0160.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0071.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0142.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0191.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0105.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0188.txt\n",
            "Removed: /content/split_audio/combined_chunk_0145.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0207.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0186.txt\n",
            "Removed: /content/split_audio/combined_chunk_0166.txt\n",
            "Removed: /content/split_audio/combined_chunk_0199.txt\n",
            "Removed: /content/split_audio/combined_chunk_0040.txt\n",
            "Removed: /content/split_audio/combined_chunk_0042.txt\n",
            "Removed: /content/split_audio/combined_chunk_0232.txt\n",
            "Removed: /content/split_audio/combined_chunk_0047.txt\n",
            "Removed: /content/split_audio/combined_chunk_0173.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0123.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0088.txt\n",
            "Removed: /content/split_audio/combined_chunk_0238.txt\n",
            "Removed: /content/split_audio/combined_chunk_0135.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0065.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0216.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0221.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0114.txt\n",
            "Removed: /content/split_audio/combined_chunk_0024.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0052.txt\n",
            "Removed: /content/split_audio/combined_chunk_0157.txt\n",
            "Removed: /content/split_audio/combined_chunk_0198.txt\n",
            "Removed: /content/split_audio/combined_chunk_0011.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0115.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0245.txt\n",
            "Removed: /content/split_audio/combined_chunk_0224.txt\n",
            "Removed: /content/split_audio/combined_chunk_0059.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0171.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0169.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0237.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0019.txt\n",
            "Removed: /content/split_audio/combined_chunk_0069.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0230.txt\n",
            "Removed: /content/split_audio/combined_chunk_0217.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0028.txt\n",
            "Removed: /content/split_audio/combined_chunk_0111.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0155.txt\n",
            "Removed: /content/split_audio/combined_chunk_0065.txt\n",
            "Removed: /content/split_audio/combined_chunk_0186.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0145.txt\n",
            "Removed: /content/split_audio/combined_chunk_0120.txt\n",
            "Removed: /content/split_audio/combined_chunk_0137.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0196.txt\n",
            "Removed: /content/split_audio/combined_chunk_0109.txt\n",
            "Removed: /content/split_audio/combined_chunk_0127.txt\n",
            "Removed: /content/split_audio/combined_chunk_0031.txt\n",
            "Removed: /content/split_audio/combined_chunk_0027.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0226.txt\n",
            "Removed: /content/split_audio/combined_chunk_0139.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0208.txt\n",
            "Removed: /content/split_audio/combined_chunk_0130.txt\n",
            "Removed: /content/split_audio/combined_chunk_0133.txt\n",
            "Removed: /content/split_audio/combined_chunk_0095.txt\n",
            "Removed: /content/split_audio/combined_chunk_0118.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0242.txt\n",
            "Removed: /content/split_audio/combined_chunk_0249.txt\n",
            "Removed: /content/split_audio/combined_chunk_0007.txt\n",
            "Removed: /content/split_audio/combined_chunk_0195.txt\n",
            "Removed: /content/split_audio/combined_chunk_0245.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0131.txt\n",
            "Removed: /content/split_audio/combined_chunk_0171.txt\n",
            "Removed: /content/split_audio/combined_chunk_0041.txt\n",
            "Removed: /content/split_audio/combined_chunk_0217.txt\n",
            "Removed: /content/split_audio/combined_chunk_0207.txt\n",
            "Removed: /content/split_audio/combined_chunk_0015.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0010.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0115.txt\n",
            "Removed: /content/split_audio/combined_chunk_0156.txt\n",
            "Removed: /content/split_audio/combined_chunk_0239.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0228.txt\n",
            "Removed: /content/split_audio/combined_chunk_0244.txt\n",
            "Removed: /content/split_audio/combined_chunk_0034.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0014.txt\n",
            "Removed: /content/split_audio/combined_chunk_0125.txt\n",
            "Removed: /content/split_audio/combined_chunk_0227.txt\n",
            "Removed: /content/split_audio/combined_chunk_0181.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0056.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0022.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0178.txt\n",
            "Removed: /content/split_audio/combined_chunk_0221.txt\n",
            "Removed: /content/split_audio/combined_chunk_0144.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0036.txt\n",
            "Removed: /content/split_audio/combined_chunk_0172.txt\n",
            "Removed: /content/split_audio/combined_chunk_0126.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0101.txt\n",
            "Removed: /content/split_audio/combined_chunk_0111.txt\n",
            "Removed: /content/split_audio/combined_chunk_0161.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0132.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0081.txt\n",
            "Removed: /content/split_audio/combined_chunk_0243.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0247.txt\n",
            "Removed: /content/split_audio/combined_chunk_0191.txt\n",
            "Removed: /content/split_audio/combined_chunk_0143.txt\n",
            "Removed: /content/split_audio/combined_chunk_0128.txt\n",
            "Removed: /content/split_audio/combined_chunk_0013.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0039.txt\n",
            "Removed: /content/split_audio/combined_chunk_0165.txt\n",
            "Removed: /content/split_audio/combined_chunk_0231.txt\n",
            "Removed: /content/split_audio/combined_chunk_0050.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0165.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0175.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0240.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0233.txt\n",
            "Removed: /content/split_audio/combined_chunk_0147.txt\n",
            "Removed: /content/split_audio/combined_chunk_0083.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0170.txt\n",
            "Removed: /content/split_audio/combined_chunk_0030.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0166.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0058.txt\n",
            "Removed: /content/split_audio/combined_chunk_0018.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0209.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0012.txt\n",
            "Removed: /content/split_audio/combined_chunk_0187.txt\n",
            "Removed: /content/split_audio/combined_chunk_0077.txt\n",
            "Removed: /content/split_audio/combined_chunk_0130.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0026.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0029.txt\n",
            "Removed: /content/split_audio/combined_chunk_0098.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0237.txt\n",
            "Removed: /content/split_audio/combined_chunk_0013.txt\n",
            "Removed: /content/split_audio/combined_chunk_0045.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0212.txt\n",
            "Removed: /content/split_audio/combined_chunk_0179.txt\n",
            "Removed: /content/split_audio/combined_chunk_0090.txt\n",
            "Removed: /content/split_audio/combined_chunk_0123.txt\n",
            "Removed: /content/split_audio/combined_chunk_0011.txt\n",
            "Removed: /content/split_audio/combined_chunk_0196.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0139.txt\n",
            "Removed: /content/split_audio/combined_chunk_0078.txt\n",
            "Removed: /content/split_audio/combined_chunk_0161.txt\n",
            "Removed: /content/split_audio/combined_chunk_0117.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0199.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0067.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0081.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0039.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0152.txt\n",
            "Removed: /content/split_audio/combined_chunk_0010.txt\n",
            "Removed: /content/split_audio/combined_chunk_0213.txt\n",
            "Removed: /content/split_audio/combined_chunk_0053.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0164.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0085.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0057.txt\n",
            "Removed: /content/split_audio/combined_chunk_0112.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0021.txt\n",
            "Removed: /content/split_audio/combined_chunk_0135.txt\n",
            "Removed: /content/split_audio/combined_chunk_0033.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0141.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0212.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0184.txt\n",
            "Removed: /content/split_audio/combined_chunk_0218.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0116.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0079.txt\n",
            "Removed: /content/split_audio/combined_chunk_0107.txt\n",
            "Removed: /content/split_audio/combined_chunk_0240.txt\n",
            "Removed: /content/split_audio/combined_chunk_0229.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0071.txt\n",
            "Removed: /content/split_audio/combined_chunk_0174.txt\n",
            "Removed: /content/split_audio/combined_chunk_0150.txt\n",
            "Removed: /content/split_audio/combined_chunk_0189.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0158.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0140.txt\n",
            "Removed: /content/split_audio/combined_chunk_0053.txt\n",
            "Removed: /content/split_audio/combined_chunk_0192.txt\n",
            "Removed: /content/split_audio/combined_chunk_0122.txt\n",
            "Removed: /content/split_audio/combined_chunk_0175.txt\n",
            "Removed: /content/split_audio/combined_chunk_0069.txt\n",
            "Removed: /content/split_audio/combined_chunk_0177.txt\n",
            "Removed: /content/split_audio/combined_chunk_0060.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0075.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0023.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0096.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0087.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0052.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0086.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0142.txt\n",
            "Removed: /content/split_audio/combined_chunk_0018.txt\n",
            "Removed: /content/split_audio/combined_chunk_0080.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0214.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0020.txt\n",
            "Removed: /content/split_audio/combined_chunk_0103.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0008.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0024.txt\n",
            "Removed: /content/split_audio/combined_chunk_0147.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0225.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0064.txt\n",
            "Removed: /content/split_audio/combined_chunk_0046.txt\n",
            "Removed: /content/split_audio/combined_chunk_0234.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0037.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0210.txt\n",
            "Removed: /content/split_audio/combined_chunk_0008.txt\n",
            "Removed: /content/split_audio/combined_chunk_0201.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0033.txt\n",
            "Removed: /content/split_audio/combined_chunk_0246.txt\n",
            "Removed: /content/split_audio/combined_chunk_0190.txt\n",
            "Removed: /content/split_audio/combined_chunk_0045.txt\n",
            "Removed: /content/split_audio/combined_chunk_0216.txt\n",
            "Removed: /content/split_audio/combined_chunk_0109.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0132.txt\n",
            "Removed: /content/split_audio/combined_chunk_0157.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0246.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0015.txt\n",
            "Removed: /content/split_audio/combined_chunk_0089.txt\n",
            "Removed: /content/split_audio/combined_chunk_0154.txt\n",
            "Removed: /content/split_audio/combined_chunk_0014.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0178.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0056.txt\n",
            "Removed: /content/split_audio/combined_chunk_0204.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0112.txt\n",
            "Removed: /content/split_audio/combined_chunk_0023.txt\n",
            "Removed: /content/split_audio/combined_chunk_0038.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0119.txt\n",
            "Removed: /content/split_audio/combined_chunk_0007.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0138.txt\n",
            "Removed: /content/split_audio/combined_chunk_0121.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0012.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0049.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0095.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0083.txt\n",
            "Removed: /content/split_audio/combined_chunk_0051.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0087.txt\n",
            "Removed: /content/split_audio/combined_chunk_0097.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0227.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0054.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0074.txt\n",
            "Removed: /content/split_audio/combined_chunk_0030.txt\n",
            "Removed: /content/split_audio/combined_chunk_0125.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0021.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0075.txt\n",
            "Removed: /content/split_audio/combined_chunk_0088.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0028.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0017.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0160.txt\n",
            "Removed: /content/split_audio/combined_chunk_0167.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0102.txt\n",
            "Removed: /content/split_audio/combined_chunk_0168.txt\n",
            "Removed: /content/split_audio/combined_chunk_0117.txt\n",
            "Removed: /content/split_audio/combined_chunk_0163.txt\n",
            "Removed: /content/split_audio/combined_chunk_0225.txt\n",
            "Removed: /content/split_audio/combined_chunk_0150.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0118.txt\n",
            "Removed: /content/split_audio/combined_chunk_0055.txt\n",
            "Removed: /content/split_audio/combined_chunk_0108.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0197.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0076.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0233.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0188.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0073.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0113.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0244.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0099.txt\n",
            "Removed: /content/split_audio/combined_chunk_0210.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0068.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0141.txt\n",
            "Removed: /content/split_audio/combined_chunk_0170.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0046.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0110.txt\n",
            "Removed: /content/split_audio/combined_chunk_0215.txt\n",
            "Removed: /content/split_audio/combined_chunk_0119.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0068.txt\n",
            "Removed: /content/split_audio/combined_chunk_0136.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0037.txt\n",
            "Removed: /content/split_audio/combined_chunk_0077.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0155.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0152.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0107.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0167.txt\n",
            "Removed: /content/split_audio/combined_chunk_0093.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0189.txt\n",
            "Removed: /content/split_audio/combined_chunk_0153.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0222.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0020.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0016.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0100.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0241.txt\n",
            "Removed: /content/split_audio/combined_chunk_0035.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0047.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0060.txt\n",
            "Removed: /content/split_audio/combined_chunk_0126.txt\n",
            "Removed: /content/split_audio/combined_chunk_0218.txt\n",
            "Removed: /content/split_audio/combined_chunk_0102.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0183.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0190.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0202.txt\n",
            "Removed: /content/split_audio/combined_chunk_0098.txt\n",
            "Removed: /content/split_audio/combined_chunk_0127.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0215.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0073.txt\n",
            "Removed: /content/split_audio/combined_chunk_0091.txt\n",
            "Removed: /content/split_audio/combined_chunk_0163.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0200.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0231.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0128.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0034.txt\n",
            "Removed: /content/split_audio/combined_chunk_0080.txt\n",
            "Removed: /content/split_audio/combined_chunk_0208.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0027.txt\n",
            "Removed: /content/split_audio/combined_chunk_0041.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0179.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0025.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0137.txt\n",
            "Removed: /content/split_audio/combined_chunk_0090.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0205.txt\n",
            "Removed: /content/split_audio/combined_chunk_0114.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0187.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0169.txt\n",
            "Removed: /content/split_audio/combined_chunk_0180.txt\n",
            "Removed: /content/split_audio/combined_chunk_0172.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0242.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0044.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0149.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0158.txt\n",
            "Removed: /content/split_audio/combined_chunk_0061.txt\n",
            "Removed: /content/split_audio/combined_chunk_0032.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0181.txt\n",
            "Removed: /content/split_audio/combined_chunk_0035.txt\n",
            "Removed: /content/split_audio/combined_chunk_0184.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0193.txt\n",
            "Removed: /content/split_audio/combined_chunk_0185.txt\n",
            "Removed: /content/split_audio/combined_chunk_0092.txt\n",
            "Removed: /content/split_audio/combined_chunk_0146.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0050.txt\n",
            "Removed: /content/split_audio/combined_chunk_0092.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0032.txt\n",
            "Removed: /content/split_audio/combined_chunk_0017.txt\n",
            "Removed: /content/split_audio/combined_chunk_0103.txt\n",
            "Removed: /content/split_audio/combined_chunk_0153.txt\n",
            "Removed: /content/split_audio/combined_chunk_0121.txt\n",
            "Removed: /content/split_audio/combined_chunk_0173.txt\n",
            "Removed: /content/split_audio/combined_chunk_0094.txt\n",
            "Removed: /content/split_audio/combined_chunk_0094.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0131.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0129.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0054.txt\n",
            "Removed: /content/split_audio/combined_chunk_0162.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0247.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0176.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0168.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0211.txt\n",
            "Removed: /content/split_audio/combined_chunk_0124.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0236.txt\n",
            "Removed: /content/split_audio/combined_chunk_0228.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0211.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0093.txt\n",
            "Removed: /content/split_audio/combined_chunk_0058.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0078.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0113.txt\n",
            "Removed: /content/split_audio/combined_chunk_0159.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0235.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0198.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0043.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0031.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0059.txt\n",
            "Removed: /content/split_audio/combined_chunk_0148.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0044.txt\n",
            "Removed: /content/split_audio/combined_chunk_0224.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0084.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0223.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0096.txt\n",
            "Removed: /content/split_audio/combined_chunk_0085.txt\n",
            "Removed: /content/split_audio/combined_chunk_0134.txt\n",
            "Removed: /content/split_audio/combined_chunk_0116.txt\n",
            "Removed: /content/split_audio/combined_chunk_0195.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0206.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0213.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0048.txt\n",
            "Removed: /content/split_audio/combined_chunk_0176.txt\n",
            "Removed: /content/split_audio/combined_chunk_0230.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0129.txt\n",
            "Removed: /content/split_audio/combined_chunk_0061.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0022.txt\n",
            "Removed: /content/split_audio/combined_chunk_0120.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0086.txt\n",
            "Removed: /content/split_audio/combined_chunk_0062.txt\n",
            "Removed: /content/split_audio/combined_chunk_0070.txt\n",
            "Removed: /content/split_audio/combined_chunk_0048.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0220.txt\n",
            "Removed: /content/split_audio/combined_chunk_0154.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0036.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0072.txt\n",
            "Removed: /content/split_audio/combined_chunk_0229.txt\n",
            "Removed: /content/split_audio/combined_chunk_0042.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0040.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0205.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0009.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0151.txt\n",
            "Removed: /content/split_audio/combined_chunk_0104.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0100.txt\n",
            "Removed: /content/split_audio/combined_chunk_0106.txt\n",
            "Removed: /content/split_audio/combined_chunk_0143.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0110.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0144.txt\n",
            "Removed: /content/split_audio/combined_chunk_0140.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0194.txt\n",
            "Removed: /content/split_audio/combined_chunk_0019.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0138.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0159.txt\n",
            "Removed: /content/split_audio/combined_chunk_0226.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0101.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0223.txt\n",
            "Removed: /content/split_audio/combined_chunk_0202.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0164.txt\n",
            "Removed: /content/split_audio/combined_chunk_0151.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0063.txt\n",
            "Removed: /content/split_audio/combined_chunk_0201.txt\n",
            "Removed: /content/split_audio/combined_chunk_0136.txt\n",
            "Removed: /content/split_audio/combined_chunk_0074.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0076.txt\n",
            "Removed: /content/split_audio/combined_chunk_0105.txt\n",
            "Removed: /content/split_audio/combined_chunk_0122.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0043.txt\n",
            "Removed: /content/split_audio/combined_chunk_0099.mp3\n",
            "Removed: /content/split_audio/combined_chunk_0066.mp3\n",
            "Files starting from combined_chunk_0006 and onwards have been removed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z2uftYj-FPBy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}